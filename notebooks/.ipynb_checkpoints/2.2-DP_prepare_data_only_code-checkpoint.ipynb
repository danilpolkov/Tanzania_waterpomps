{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import pygal\n",
    "from IPython.display import display, HTML\n",
    "from pygal.style import Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danylopoliakov/Documents/GitHub/Tanzania_waterpomps\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danylopoliakov/Documents/GitHub/Tanzania_waterpomps/data/raw\n"
     ]
    }
   ],
   "source": [
    "cd data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "target = pd.read_csv('target.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train[['amount_tsh', 'num_private', 'population' ,'construction_year']] = \\\n",
    "    train[['amount_tsh', 'num_private', 'population' ,'construction_year']].replace(0, np.NaN)\n",
    "\n",
    "train.drop(['wpt_name', 'recorded_by', 'longitude', 'latitude','scheme_name', 'num_private'], 1, inplace=True)\n",
    "\n",
    "train[['region_code', 'district_code']]= train[['region_code', 'district_code']].astype('object')\n",
    "train[['date_recorded', 'construction_year']]= train[['date_recorded', 'construction_year']].apply((pd.to_datetime))\n",
    "\n",
    "categoricals = train.select_dtypes(include = ['object']).columns.tolist()\n",
    "numerical = train.select_dtypes(include = ['int', 'float']).columns.tolist()\n",
    "date_cols = train.select_dtypes(include = ['datetime64']).columns.tolist()\n",
    "\n",
    "df = pd.merge(train, target, how = 'inner', on = 'id')\n",
    "\n",
    "df.drop('id', 1, inplace=True)\n",
    "\n",
    "df['missed_population'] = np.where(np.isnan(df['population']), 1, 0)\n",
    "df['population'].fillna(0, inplace = True)\n",
    "\n",
    "df.isnull().amount_tsh.sum()\n",
    "\n",
    "df['approximated_amount_tsh'] = np.where(np.isnan(df['amount_tsh']), 1, 0) \n",
    "replacements = df.groupby('water_quality').amount_tsh.agg(pd.Series.mode).to_dict()\n",
    "\n",
    "# all vlaues amount_tsh in this category is Nan\n",
    "replacements.pop('fluoride abandoned')\n",
    "\n",
    "df.loc[df['water_quality'] != 'soft', 'amount_tsh'] = \\\n",
    "    df.loc[df['water_quality'] != 'soft', 'amount_tsh'].fillna(replacements)\n",
    "\n",
    "df['amount_tsh'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wrong_gps_height'] = np.where(df['gps_height'] < 0, 1, 0) \n",
    "df['gps_height'] = abs(df['gps_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categoricals] = df[categoricals].astype('str')\n",
    "df[categoricals] = df[categoricals].applymap(lambda x: x.lower())\n",
    "nan_list = ['not known','unknown','none','-','##','not kno','unknown installer', '0', 'dwe']\n",
    "df = df.replace(nan_list, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_in_subvillages = df['subvillage'].value_counts().to_dict()\n",
    "df['wp_in_subvillage'] = df['subvillage'].replace(wp_in_subvillages)\n",
    "df['wp_in_subvillage'].fillna(1, inplace=True)\n",
    "\n",
    "wp_in_lga = df['lga'].value_counts().to_dict()\n",
    "df['wp_in_lga'] = df['lga'].replace(wp_in_lga)\n",
    "\n",
    "wp_in_ward = df['ward'].value_counts().to_dict()\n",
    "df['wp_in_ward'] = df['ward'].replace(wp_in_ward)\n",
    "\n",
    "df.drop(['subvillage', 'lga', 'ward'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(include = ['object']).columns.tolist()\n",
    "# Any feature values with fewer than 50 rows would be turned into a 'other'\n",
    "for feature in df[categoricals]:\n",
    "    # Determine which feature values to keep\n",
    "    remove = df[feature].value_counts()[df[feature].value_counts() < 50].index.tolist()\n",
    "    #print(remove)\n",
    "    #to_keep = train[feature].value_counts()[train[feature].value_counts() > 50].index.tolist()\n",
    "    \n",
    "    # Turn those into NANs (using a copy, to prevent warnings)\n",
    "    feature_copy = df[feature].copy()\n",
    "    #feature_copy[~feature_copy.isin(to_keep)] = np.nan\n",
    "    feature_copy[feature_copy.isin(remove)] = np.nan\n",
    "    #print(feature_copy.isnull().sum())\n",
    "    df[feature] = feature_copy\n",
    "# Fix all NANs\n",
    "df[categoricals] = df[categoricals].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I checked that Tanzania has 31 region, so I will drop column 'region', beckause there is less values\n",
    "df.drop(['region', 'district_code'], 1, inplace=True)\n",
    "\n",
    "# extraction_type has very close values with extraction_type_group and extraction_type_class but extraction_type\n",
    "# has more values so I will \n",
    "# remove extraction_type_group, extraction_type_class\n",
    "\n",
    "df.drop('extraction_type_group', 1, inplace=True)\n",
    "df.drop('extraction_type_class', 1, inplace=True)\n",
    "\n",
    "# majority of 'management' looks the same so I will remove this columns and leave 'management_group' \n",
    "# and join small columns to 'other' \n",
    "df.management_group = df.management_group.apply(lambda x: 'other' if x != 'user-group' else x)\n",
    "\n",
    "# need to check shares in groups but nice and remove it\n",
    "# distribution in classes looks the same and this is not informative, will remove it\n",
    "df.drop(['management', 'management_group'], 1, inplace=True)\n",
    "\n",
    "# join pay to 1 group and others to another\n",
    "unpayable_types = ['never pay', 'other']\n",
    "df.payment = df.payment.apply(lambda x: 0 if x in unpayable_types else 1)\n",
    "df['payment']= df['payment'].astype('object')\n",
    "\n",
    "df.drop('payment_type', 1, inplace=True)\n",
    "# beckause payment shows the same info\n",
    "\n",
    "# quality_group looks very close to water_quality, so I will remove one\n",
    "df.drop(['water_quality'], 1, inplace=True)\n",
    "\n",
    "# quantity_group and quantity have the same info, so I will remove second one and join 'other' with 'dry' \n",
    "# beckause it small group\n",
    "df.drop(['quantity_group'], 1, inplace=True)\n",
    "\n",
    "#df.quantity = \n",
    "df.quantity.replace({'dry': 'other'}, inplace=True)\n",
    "\n",
    "# I will drop source_class and source_type becuase source is more detailed\n",
    "df.drop(['source_class', 'source_type'], 1, inplace=True)\n",
    "\n",
    "# waterpoint_type_group and waterpoint_type looks the same but  waterpoint_type more detailed\n",
    "df.drop('waterpoint_type_group', 1, inplace=True)\n",
    "\n",
    "# I will join 2 small classes with close distribution\n",
    "df.waterpoint_type.replace({'cattle trough':'improved spring'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.construction_year.fillna(0, inplace=True)\n",
    "df.construction_year = df.construction_year.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.construction_year = df.construction_year.replace(0, np.NaN)\n",
    "# add column that means that construction_year was filled with approximation\n",
    "df['approximated_construction_year'] = df['construction_year'].apply(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "replacements = df.groupby(['funder', 'installer'])['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "replacements = df.groupby('installer')['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "replacements = df.groupby('funder')['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "df.construction_year.fillna(df.construction_year.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lifetimes'] = df['date_recorded'].dt.year - df['construction_year']\n",
    "df['lifetimes'] = np.where(df['lifetimes'] < 0, 0, df['lifetimes'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date_recorded', 'construction_year'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('prepeared_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['wp_in_subvillage'] = df['wp_in_subvillage'].astype(int)\n",
    "df['payment']= df['payment'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danylopoliakov/Documents/GitHub/Tanzania_waterpomps/data/processed\n"
     ]
    }
   ],
   "source": [
    "cd processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mprocessed\u001b[m\u001b[m/   \u001b[34mraw\u001b[m\u001b[m/         \u001b[34msubmissions\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danylopoliakov/.local/share/virtualenvs/Tanzania_waterpomps-ojV3XnUo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prepeared_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                        float64\n",
       "funder                             object\n",
       "gps_height                          int64\n",
       "installer                          object\n",
       "basin                              object\n",
       "region_code                        object\n",
       "population                        float64\n",
       "public_meeting                     object\n",
       "scheme_management                  object\n",
       "permit                             object\n",
       "extraction_type                    object\n",
       "payment                             int64\n",
       "quality_group                      object\n",
       "quantity                           object\n",
       "source                             object\n",
       "waterpoint_type                    object\n",
       "status_group                       object\n",
       "missed_population                   int64\n",
       "approximated_amount_tsh             int64\n",
       "wrong_gps_height                    int64\n",
       "wp_in_subvillage                  float64\n",
       "wp_in_lga                           int64\n",
       "wp_in_ward                          int64\n",
       "approximated_construction_year      int64\n",
       "lifetimes                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ww cat features\n",
    "1. onehotencod\n",
    "give the same num of columns as dummy\n",
    "2. target_encoding\n",
    "LR: 0.669481 (0.006335)\n",
    "RF: 0.776119 (0.007765)\n",
    "3. dummy_encode\n",
    "LR: 0.746746 (0.006960)\n",
    "RF: 0.780567 (0.007248)\n",
    "4. drop unnecessury features\n",
    "selected -3\n",
    "LR: 0.730112 (0.007359)\n",
    "RF: 0.779788 (0.003643)\n",
    "ww numeric features\n",
    "1. normalize\n",
    "LR: 0.717146 (0.007618)\n",
    "RF: 0.781848 (0.005260)\n",
    "2. log\n",
    "LR: 0.719659 (0.006688)\n",
    "RF: 0.783557 (0.006206)\n",
    "3. minMax\n",
    "LR: 0.730891 (0.007700)\n",
    "RF: 0.784662 (0.005118)\n",
    "4. robust\n",
    "LR: 0.727825 (0.007459)\n",
    "RF: 0.773531 (0.004417)\n",
    "5. drop unnecessury\n",
    "ww models\n",
    "1. install xgboost or lightgbm\n",
    "2. install cat boost\n",
    "3. NN\n",
    "4. randomGridSearch for best model\n",
    "predict on test data and validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment']= df['payment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include = ['float64', 'int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['amount_tsh', 'gps_height', 'population', 'wp_in_subvillage', 'wp_in_lga', 'wp_in_ward', 'lifetimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                        float64\n",
       "funder                             object\n",
       "gps_height                          int64\n",
       "installer                          object\n",
       "basin                              object\n",
       "region_code                        object\n",
       "population                        float64\n",
       "public_meeting                     object\n",
       "scheme_management                  object\n",
       "permit                             object\n",
       "extraction_type                    object\n",
       "payment                             int64\n",
       "quality_group                      object\n",
       "quantity                           object\n",
       "source                             object\n",
       "waterpoint_type                    object\n",
       "status_group                       object\n",
       "missed_population                   int64\n",
       "approximated_amount_tsh             int64\n",
       "wrong_gps_height                    int64\n",
       "wp_in_subvillage                  float64\n",
       "wp_in_lga                           int64\n",
       "wp_in_ward                          int64\n",
       "approximated_construction_year      int64\n",
       "lifetimes                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'population',\n",
       " 'wp_in_subvillage',\n",
       " 'wp_in_lga',\n",
       " 'wp_in_ward',\n",
       " 'lifetimes']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df[numerical] = preprocessing.normalize(df[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status_group = df.status_group.replace(['functional', 'non functional', 'functional needs repair'], [2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.status_group\n",
    "train = df.drop('status_group', 1)\n",
    "numerical = train.select_dtypes(include = ['float64', 'int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "train[numerical] = preprocessing.normalize(train[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# robost\n",
    "scaler = RobustScaler()\n",
    "nums_scaled = scaler.fit_transform(df[numerical])\n",
    "nums_scaled = pd.DataFrame(nums_scaled, columns=numerical)\n",
    "df[numerical] = nums_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[numerical].values)\n",
    "train[numerical] = scaler.transform(train[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "train[numerical] = np.log(train[numerical].values)\n",
    "\n",
    "train[numerical] = train[numerical].replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = train.select_dtypes(exclude=['number']).nunique().sort_values().index.tolist()[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public_meeting',\n",
       " 'permit',\n",
       " 'quantity',\n",
       " 'waterpoint_type',\n",
       " 'quality_group',\n",
       " 'basin',\n",
       " 'source',\n",
       " 'scheme_management',\n",
       " 'extraction_type']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorial = train.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "categorial = train.select_dtypes(include = ['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funder',\n",
       " 'installer',\n",
       " 'basin',\n",
       " 'region_code',\n",
       " 'public_meeting',\n",
       " 'scheme_management',\n",
       " 'permit',\n",
       " 'extraction_type',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source',\n",
       " 'waterpoint_type']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_works = [1.0 if x == 2 else 0.0 for x in target]\n",
    "y_broken = [1.0 if x == 0 else 0.0 for x in target]\n",
    "y_repair = [1.0 if x == 1 else 0.0 for x in target]\n",
    "y_vectors = [y_works, y_broken, y_repair]\n",
    "X_TE_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TE = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to create encoding based on the training features and \n",
    "# labels, but apply this encoding to any vector (such as X_test)\n",
    "for i in [1,2,3]:\n",
    "     # Make an encoder\n",
    "    TE = TargetEncoder()\n",
    "     \n",
    "     # Fit it to the training data\n",
    "    TE.fit(X=train[categorial], y=y_vectors[i-1])\n",
    "     # Transform the cat columns in X\n",
    "    X_TE = TE.transform(train_TE[categorial])\n",
    "     \n",
    "     # Give them custom names, so that the columns encoded against\n",
    "     # each target vector have a different name\n",
    "    X_TE = X_TE.rename(columns=(lambda x: x + '_TE' + str(i)))\n",
    "    X_TE_all.append(X_TE)\n",
    "new_cats = pd.concat(X_TE_all, sort=False, axis=1)\n",
    " \n",
    "train_TE = train_TE.drop(columns=categorial)\n",
    "train_TE = pd.concat([train_TE,new_cats], sort=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>payment</th>\n",
       "      <th>missed_population</th>\n",
       "      <th>approximated_amount_tsh</th>\n",
       "      <th>wrong_gps_height</th>\n",
       "      <th>wp_in_subvillage</th>\n",
       "      <th>wp_in_lga</th>\n",
       "      <th>wp_in_ward</th>\n",
       "      <th>...</th>\n",
       "      <th>basin_TE3</th>\n",
       "      <th>region_code_TE3</th>\n",
       "      <th>public_meeting_TE3</th>\n",
       "      <th>scheme_management_TE3</th>\n",
       "      <th>permit_TE3</th>\n",
       "      <th>extraction_type_TE3</th>\n",
       "      <th>quality_group_TE3</th>\n",
       "      <th>quantity_TE3</th>\n",
       "      <th>source_TE3</th>\n",
       "      <th>waterpoint_type_TE3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>564</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>716</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>0.028683</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>308</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.064965</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.106177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>158</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.095785</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.106177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>771</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.087121</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>288</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.106177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>588</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.123623</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>836</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.123623</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>771</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.087121</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>560</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>694</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.061495</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>809</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.123623</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>434</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>468</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.123623</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>521</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.083419</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1703</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1162</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>341</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.060106</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>564</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2216</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1177</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.123623</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1510</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500.0</td>\n",
       "      <td>672</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>877</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>824</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.221769</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.096667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1273</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1251</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>500.0</td>\n",
       "      <td>200</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>388</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>771</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.087121</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>594</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.034873</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>434</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59370</th>\n",
       "      <td>200.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.205795</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59371</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>809</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>382</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59373</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>1137</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>679</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59374</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1177</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59375</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>54</td>\n",
       "      <td>609.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.058493</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.098168</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>338</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.106177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59378</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.024576</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>402</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59380</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1439</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>564</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.024576</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>288</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59382</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1251</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.076297</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59383</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.053743</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>669</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59385</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1327</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>438</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.023729</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>521</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59387</th>\n",
       "      <td>100.0</td>\n",
       "      <td>25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>497</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1414</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>874</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.205795</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.096667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>783</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>428</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1715</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>521</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>540</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>877</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.076297</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>298</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>0.107517</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>338</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071548</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59394</th>\n",
       "      <td>500.0</td>\n",
       "      <td>351</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>671</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.072647</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59395</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1210</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.076297</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59396</th>\n",
       "      <td>4700.0</td>\n",
       "      <td>1212</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.024576</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.127029</td>\n",
       "      <td>0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>626</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.107517</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>347</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.094758</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.076823</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>191</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>521</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.072647</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.078612</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59400 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh  gps_height  population  payment  missed_population  \\\n",
       "0          6000.0        1390       109.0        1                  0   \n",
       "1             0.0        1399       280.0        0                  0   \n",
       "2            25.0         686       250.0        1                  0   \n",
       "3             0.0         263        58.0        0                  0   \n",
       "4             0.0           0         0.0        0                  1   \n",
       "...           ...         ...         ...      ...                ...   \n",
       "59395        10.0        1210       125.0        1                  0   \n",
       "59396      4700.0        1212        56.0        1                  0   \n",
       "59397         0.0           0         0.0        1                  1   \n",
       "59398         0.0           0         0.0        0                  1   \n",
       "59399         0.0         191       150.0        1                  0   \n",
       "\n",
       "       approximated_amount_tsh  wrong_gps_height  wp_in_subvillage  wp_in_lga  \\\n",
       "0                            0                 0               6.0        564   \n",
       "1                            1                 0               5.0        716   \n",
       "2                            0                 0             502.0        308   \n",
       "3                            1                 0              17.0        158   \n",
       "4                            1                 0               2.0        771   \n",
       "...                        ...               ...               ...        ...   \n",
       "59395                        0                 0               4.0        625   \n",
       "59396                        0                 0              14.0       2503   \n",
       "59397                        1                 0               2.0        626   \n",
       "59398                        1                 0              24.0        347   \n",
       "59399                        1                 0               1.0        521   \n",
       "\n",
       "       wp_in_ward  ...  basin_TE3  region_code_TE3  public_meeting_TE3  \\\n",
       "0              36  ...   0.049164         0.022109            0.072906   \n",
       "1              71  ...   0.096507         0.035283            0.046791   \n",
       "2              10  ...   0.053356         0.064965            0.072906   \n",
       "3              32  ...   0.072557         0.095785            0.072906   \n",
       "4              13  ...   0.096507         0.087121            0.072906   \n",
       "...           ...  ...        ...              ...                 ...   \n",
       "59395         116  ...   0.053356         0.076297            0.072906   \n",
       "59396          53  ...   0.054789         0.024576            0.072906   \n",
       "59397          88  ...   0.054789         0.107517            0.072906   \n",
       "59398          25  ...   0.054789         0.094758            0.072906   \n",
       "59399          60  ...   0.044931         0.072647            0.072906   \n",
       "\n",
       "       scheme_management_TE3  permit_TE3  extraction_type_TE3  \\\n",
       "0                   0.063436    0.075463             0.100859   \n",
       "1                   0.028683    0.069417             0.100859   \n",
       "2                   0.063436    0.069417             0.100859   \n",
       "3                   0.063436    0.069417             0.047649   \n",
       "4                   0.057519    0.069417             0.100859   \n",
       "...                      ...         ...                  ...   \n",
       "59395               0.040393    0.069417             0.100859   \n",
       "59396               0.063436    0.069417             0.100859   \n",
       "59397               0.063436    0.075463             0.057766   \n",
       "59398               0.063436    0.069417             0.078612   \n",
       "59399               0.063436    0.069417             0.078612   \n",
       "\n",
       "       quality_group_TE3  quantity_TE3  source_TE3  waterpoint_type_TE3  \n",
       "0               0.076823      0.072320    0.074966             0.079237  \n",
       "1               0.076823      0.095842    0.136819             0.079237  \n",
       "2               0.076823      0.072320    0.036585             0.106177  \n",
       "3               0.076823      0.007249    0.044334             0.106177  \n",
       "4               0.076823      0.102716    0.136819             0.079237  \n",
       "...                  ...           ...         ...                  ...  \n",
       "59395           0.076823      0.072320    0.074966             0.079237  \n",
       "59396           0.076823      0.072320    0.127029             0.079237  \n",
       "59397           0.059908      0.072320    0.044334             0.058840  \n",
       "59398           0.076823      0.095842    0.056883             0.058840  \n",
       "59399           0.057170      0.072320    0.056883             0.058840  \n",
       "\n",
       "[59400 rows x 48 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 63)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dum = pd.get_dummies(train[cols_to_keep], dummy_na=False, prefix = cols_to_keep)\n",
    "train_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = pd.concat([train_dum, train[non_categorial]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_TE, target, test_size=0.33, random_state=42, \n",
    "                                               stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39798, 48)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import cross_validate\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.602518 (0.004845), takes: 0.895936\n",
      "RF: 0.771194 (0.004172), takes: 0.471380\n",
      "et: 0.761797 (0.002826), takes: 0.260909\n",
      "nb: 0.562240 (0.004495), takes: 0.033341\n",
      "XGBT: 0.749711 (0.003259), takes: 2.300982\n",
      "LGBM: 0.779788 (0.002153), takes: 1.186016\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(solver = 'lbfgs', multi_class='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=-1)))\n",
    "models.append(('et', ExtraTreesClassifier(n_jobs=-1)))\n",
    "models.append(('nb', BernoulliNB()))\n",
    "models.append(('XGBT', XGBClassifier(silent=True, n_jobs = -1)))\n",
    "#models.append(('CatBST', CatBoostClassifier(silent=True)))\n",
    "models.append(('LGBM', LGBMClassifier(silent=True)))\n",
    "\n",
    "\n",
    "\n",
    "#testing models\n",
    "\n",
    "accuracy_results = []\n",
    "time_to_fit = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5, random_state=42)\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    accuracy_results.append(cv_results['test_score'])\n",
    "    time_to_fit.append(cv_results['fit_time'])\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f), takes: %f' % (name, cv_results['test_score'].mean(), \n",
    "                           cv_results['test_score'].std(), \n",
    "                           cv_results['fit_time'].mean())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_model = XGBClassifier(silent=True, \n",
    "                        n_jobs = -1, objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', \n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 14, colsample_bytree = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, eta=0.1,\n",
       "              eval_metric='merror', gamma=0, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=14, maximize=False,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nrounds='min.error.idx', nthread=None, num_class=3,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "              subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_model.fit(train_TE, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([12.79254007, 13.3800509 , 13.49330878, 12.30500102, 12.72979307]),\n",
       " 'score_time': array([0.20864677, 0.25507712, 0.34816217, 0.23206615, 0.27445102]),\n",
       " 'test_score': array([0.80740741, 0.8047138 , 0.80639731, 0.80227273, 0.80723906])}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(x_model, train_TE, target, cv=kfold, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.99734282, 1.03789902, 0.98497796, 1.28987718, 1.26541281]),\n",
       " 'score_time': array([0.06579113, 0.0573051 , 0.05752301, 0.06262708, 0.05795026]),\n",
       " 'test_score': array([0.77801508, 0.77688442, 0.78077889, 0.78301294, 0.78024877])}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random search for RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 100 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed: 51.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=9,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=402,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 6)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 5)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = list(range(2, 10))\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'bootstrap': bootstrap}\n",
    "rf = RandomForestClassifier()\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rfc_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 9, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               scoring = 'accuracy',\n",
    "                               n_jobs = -1)\n",
    "rfc_random.fit(X_train, y_train)\n",
    "\n",
    "rfc_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995102540557086"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rfc_random.predict(X_test), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble for different algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('RFC',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators='warn',\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verb...\n",
       "                                             importance_type='split',\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0))],\n",
       "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell for retrained RandomSearch\n",
    "ensemble_model = VotingClassifier(estimators=[('RFC', RandomForestClassifier(n_jobs=-1)), \n",
    "                                              ('LR', LogisticRegression(solver = 'lbfgs', multi_class='auto')), \n",
    "                                              ('nb', BernoulliNB()),\n",
    "                                              ('LB', LGBMClassifier(silent=True))], voting='soft', n_jobs = -1)\n",
    "ensemble_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7761963064993368"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, ensemble_model.predict(X_test), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_to_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.602241</td>\n",
       "      <td>1.088772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.769461</td>\n",
       "      <td>0.259234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.667219</td>\n",
       "      <td>0.057029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nbg</td>\n",
       "      <td>0.538519</td>\n",
       "      <td>0.074673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.775717</td>\n",
       "      <td>0.830119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  accuracy  time_to_fit\n",
       "0    LR  0.602241     1.088772\n",
       "1    RF  0.769461     0.259234\n",
       "2    nb  0.667219     0.057029\n",
       "3   nbg  0.538519     0.074673\n",
       "4  LGBM  0.775717     0.830119"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(names, \n",
    "                      list(map(np.mean, accuracy_results)), \n",
    "                      list(map(np.mean, time_to_fit)))), \n",
    "             columns=['name', 'accuracy', 'time_to_fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124a1d048>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Compare Algorithms\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "plt.title('Comparison of Classification Algorithms')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.boxplot(results)\n",
    "#ax = fig.add_subplot(111)\n",
    "plt.xlabel(names)\n",
    "#ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.86      0.83     10719\n",
      "functional needs repair       0.48      0.35      0.40      1425\n",
      "         non functional       0.81      0.75      0.78      7458\n",
      "\n",
      "            avg / total       0.78      0.78      0.78     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAE9CAYAAAB5m7WdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIl5R6ImIVxR6IuIVhZ6IeEWhJyJe+X8EP3bq8xtx8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b90dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i,\n",
    "               s=confmat[i,j],\n",
    "               va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['public_meeting_False', 'public_meeting_True', 'permit_False',\n",
       "       'permit_True', 'quantity_enough', 'quantity_insufficient',\n",
       "       'quantity_other', 'quantity_seasonal',\n",
       "       'waterpoint_type_communal standpipe',\n",
       "       'waterpoint_type_communal standpipe multiple',\n",
       "       'waterpoint_type_hand pump', 'waterpoint_type_improved spring',\n",
       "       'waterpoint_type_other', 'quality_group_colored',\n",
       "       'quality_group_fluoride', 'quality_group_good',\n",
       "       'quality_group_milky', 'quality_group_other', 'quality_group_salty',\n",
       "       'basin_internal', 'basin_lake nyasa', 'basin_lake rukwa',\n",
       "       'basin_lake tanganyika', 'basin_lake victoria', 'basin_pangani',\n",
       "       'basin_rufiji', 'basin_ruvuma / southern coast',\n",
       "       'basin_wami / ruvu', 'source_dam', 'source_hand dtw', 'source_lake',\n",
       "       'source_machine dbh', 'source_other', 'source_rainwater harvesting',\n",
       "       'source_river', 'source_shallow well', 'source_spring',\n",
       "       'scheme_management_company', 'scheme_management_other',\n",
       "       'scheme_management_parastatal',\n",
       "       'scheme_management_private operator', 'scheme_management_swc',\n",
       "       'scheme_management_trust', 'scheme_management_vwc',\n",
       "       'scheme_management_water authority',\n",
       "       'scheme_management_water board', 'scheme_management_wua',\n",
       "       'scheme_management_wug', 'extraction_type_afridev',\n",
       "       'extraction_type_cemo', 'extraction_type_gravity',\n",
       "       'extraction_type_india mark ii', 'extraction_type_india mark iii',\n",
       "       'extraction_type_ksb', 'extraction_type_mono',\n",
       "       'extraction_type_nira/tanira', 'extraction_type_other',\n",
       "       'extraction_type_other - play pump',\n",
       "       'extraction_type_other - rope pump',\n",
       "       'extraction_type_other - swn 81', 'extraction_type_submersible',\n",
       "       'extraction_type_swn 80', 'extraction_type_windmill', 'amount_tsh',\n",
       "       'gps_height', 'population', 'payment', 'missed_population',\n",
       "       'approximated_amount_tsh', 'wrong_gps_height', 'wp_in_subvillage',\n",
       "       'wp_in_lga', 'wp_in_ward', 'approximated_construction_year',\n",
       "       'lifetimes'],\n",
       "      dtype='<U43')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_lb.feature_importances_,\n",
    "             index = X_train.columns,\n",
    "             columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from second how to make pipeline and use H2ORandomForest\n",
    "# concat train and test when we work with data, but in the end separeti them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_numeric_features(df):\n",
    "    df['missed_population'] = np.where(np.isnan(df['population']), 1, 0)\n",
    "    df['population'].fillna(0, inplace = True)\n",
    "    df['approximated_amount_tsh'] = np.where(np.isnan(df['amount_tsh']), 1, 0) \n",
    "    replacements = df.groupby('water_quality').amount_tsh.agg(pd.Series.mode).to_dict()\n",
    "    replacements.pop('fluoride abandoned')\n",
    "    df.loc[df['water_quality'] != 'soft', 'amount_tsh'] = \\\n",
    "        df.loc[df['water_quality'] != 'soft', 'amount_tsh'].fillna(replacements)\n",
    "    df['amount_tsh'].fillna(0, inplace=True)\n",
    "    df['wrong_gps_height'] = np.where(df['gps_height'] < 0, 1, 0) \n",
    "    df['gps_height'] = abs(df['gps_height'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_categorical_features(df, categoricals):\n",
    "    df[categoricals] = df[categoricals].astype('str')\n",
    "    df[categoricals] = df[categoricals].applymap(lambda x: x.lower())\n",
    "    nan_list = ['not known','unknown','none','-','##','not kno','unknown installer', '0', 'dwe']\n",
    "    df = df.replace(nan_list, np.nan)\n",
    "\n",
    "    # Any feature values with fewer than 50 rows would be turned into a 'other'\n",
    "    for feature in df[categoricals]:\n",
    "        # Determine which feature values to keep\n",
    "        remove = df[feature].value_counts()[df[feature].value_counts() < 50].index.tolist()\n",
    "        #print(remove)\n",
    "        #to_keep = train[feature].value_counts()[train[feature].value_counts() > 50].index.tolist()\n",
    "\n",
    "        # Turn those into NANs (using a copy, to prevent warnings)\n",
    "        feature_copy = df[feature].copy()\n",
    "        #feature_copy[~feature_copy.isin(to_keep)] = np.nan\n",
    "        feature_copy[feature_copy.isin(remove)] = np.nan\n",
    "        #print(feature_copy.isnull().sum())\n",
    "        df[feature] = feature_copy\n",
    "    # Fix all NANs\n",
    "    df[categoricals] = df[categoricals].fillna('other') \n",
    "    df.management_group = df.management_group.apply(lambda x: 'other' if x != 'user-group' else x)\n",
    "    unpayable_types = ['never pay', 'other']\n",
    "    df.payment = df.payment.apply(lambda x: 0 if x in unpayable_types else 1)\n",
    "    df.quantity.replace({'dry': 'other'}, inplace=True)\n",
    "    df.waterpoint_type.replace({'cattle trough':'improved spring'}, inplace=True)\n",
    "    df.drop(['region', 'district_code', 'extraction_type_group', 'extraction_type_class', 'management', \n",
    "             'management_group', 'payment_type', 'water_quality', 'quantity_group', 'source_class', 'source_type',\n",
    "             'waterpoint_type_group'], 1, inplace=True)\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data_features(test_df, train_df):\n",
    "    train_df_temp = train_df.copy()\n",
    "    test_df[['date_recorded', 'construction_year']]= test_df[['date_recorded', 'construction_year']].apply((pd.to_datetime))\n",
    "    train_df_temp['id'] = 0\n",
    "    df = test_df.append(train_df_temp)\n",
    "    df.construction_year.fillna(0, inplace=True)\n",
    "    df.construction_year = df.construction_year.astype(int)\n",
    "    df.construction_year = df.construction_year.replace(0, np.NaN)\n",
    "    df['approximated_construction_year'] = df['construction_year'].apply(lambda x: 1 if np.isnan(x) else 0)\n",
    "    replacements = df.groupby(['funder', 'installer'])['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    replacements = df.groupby('installer')['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    replacements = df.groupby('funder')['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    df.construction_year.fillna(df.construction_year.mode()[0], inplace=True)\n",
    "\n",
    "    return df[df.id != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_numeric_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_categorical_features(test_prep, categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_data_features(test_prep, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of 'prefix' (12) did not match the length of the columns being encoded (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-aee6b873864a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dum_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dum_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                                                        len(columns_to_encode)))\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix_sep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mcheck_len\u001b[0;34m(item, name)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                     raise ValueError(length_msg.format(name, len(item),\n\u001b[0;32m-> 1184\u001b[0;31m                                                        len(columns_to_encode)))\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of 'prefix' (12) did not match the length of the columns being encoded (32)."
     ]
    }
   ],
   "source": [
    "train_dum_t = pd.get_dummies(test_prep, dummy_na=False, prefix = categorial)\n",
    "train_dum_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 4153)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        50785\n",
       "1        51630\n",
       "2        17168\n",
       "3        45559\n",
       "4        49871\n",
       "5        52449\n",
       "6        24806\n",
       "7        28965\n",
       "8        36301\n",
       "9        54122\n",
       "10         419\n",
       "11       45750\n",
       "12         653\n",
       "13       14017\n",
       "14       44607\n",
       "15       40228\n",
       "16       27714\n",
       "17       28785\n",
       "18       28330\n",
       "19       18532\n",
       "20       69961\n",
       "21       55083\n",
       "22        8691\n",
       "23       30331\n",
       "24       70970\n",
       "25       61136\n",
       "26       28799\n",
       "27       46825\n",
       "28       44718\n",
       "29       37350\n",
       "         ...  \n",
       "14820    52228\n",
       "14821    70038\n",
       "14822    25901\n",
       "14823    21131\n",
       "14824    26580\n",
       "14825    66059\n",
       "14826    32944\n",
       "14827    13686\n",
       "14828     8471\n",
       "14829    19620\n",
       "14830    74162\n",
       "14831    37994\n",
       "14832    71151\n",
       "14833    45017\n",
       "14834    12592\n",
       "14835    58693\n",
       "14836    57539\n",
       "14837    71252\n",
       "14838     7869\n",
       "14839    57316\n",
       "14840    59757\n",
       "14841    64579\n",
       "14842    57731\n",
       "14843    65541\n",
       "14844    68174\n",
       "14845    39307\n",
       "14846    18990\n",
       "14847    28749\n",
       "14848    33492\n",
       "14849    68707\n",
       "Name: id, Length: 14850, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prep.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use get_dummies for test and train togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Kwa Mzee Chagala'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-685d205f83e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    298\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Kwa Mzee Chagala'"
     ]
    }
   ],
   "source": [
    "pred = lrc.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### or date recorder could be limitation of construction year\n",
    "# Any feature values with fewer than 50 rows gets turned into a NAN, but this value better to test on cross-validation\n",
    "# later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
