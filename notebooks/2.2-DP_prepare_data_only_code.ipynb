{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pygal\n",
    "from IPython.display import display, HTML\n",
    "from pygal.style import Style\n",
    "\n",
    "# for modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "target = pd.read_csv('target.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train[['amount_tsh', 'num_private', 'population' ,'construction_year']] = \\\n",
    "    train[['amount_tsh', 'num_private', 'population' ,'construction_year']].replace(0, np.NaN)\n",
    "\n",
    "train.drop(['wpt_name', 'recorded_by', 'longitude', 'latitude','scheme_name', 'num_private'], 1, inplace=True)\n",
    "\n",
    "train[['region_code', 'district_code']]= train[['region_code', 'district_code']].astype('object')\n",
    "train[['date_recorded', 'construction_year']]= train[['date_recorded', 'construction_year']].apply((pd.to_datetime))\n",
    "\n",
    "categoricals = train.select_dtypes(include = ['object']).columns.tolist()\n",
    "numerical = train.select_dtypes(include = ['int', 'float']).columns.tolist()\n",
    "date_cols = train.select_dtypes(include = ['datetime64']).columns.tolist()\n",
    "\n",
    "df = pd.merge(train, target, how = 'inner', on = 'id')\n",
    "\n",
    "df.drop('id', 1, inplace=True)\n",
    "\n",
    "df['missed_population'] = np.where(np.isnan(df['population']), 1, 0)\n",
    "df['population'].fillna(0, inplace = True)\n",
    "\n",
    "df.isnull().amount_tsh.sum()\n",
    "\n",
    "df['approximated_amount_tsh'] = np.where(np.isnan(df['amount_tsh']), 1, 0) \n",
    "replacements = df.groupby('water_quality').amount_tsh.agg(pd.Series.mode).to_dict()\n",
    "\n",
    "# all vlaues amount_tsh in this category is Nan\n",
    "replacements.pop('fluoride abandoned')\n",
    "\n",
    "df.loc[df['water_quality'] != 'soft', 'amount_tsh'] = \\\n",
    "    df.loc[df['water_quality'] != 'soft', 'amount_tsh'].fillna(replacements)\n",
    "\n",
    "df['amount_tsh'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['wrong_gps_height'] = np.where(df['gps_height'] < 0, 1, 0) \n",
    "df['gps_height'] = abs(df['gps_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[categoricals] = df[categoricals].astype('str')\n",
    "df[categoricals] = df[categoricals].applymap(lambda x: x.lower())\n",
    "nan_list = ['not known','unknown','none','-','##','not kno','unknown installer', '0', 'dwe']\n",
    "df = df.replace(nan_list, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wp_in_subvillages = df['subvillage'].value_counts().to_dict()\n",
    "df['wp_in_subvillage'] = df['subvillage'].replace(wp_in_subvillages)\n",
    "df['wp_in_subvillage'].fillna(1, inplace=True)\n",
    "\n",
    "wp_in_lga = df['lga'].value_counts().to_dict()\n",
    "df['wp_in_lga'] = df['lga'].replace(wp_in_lga)\n",
    "\n",
    "wp_in_ward = df['ward'].value_counts().to_dict()\n",
    "df['wp_in_ward'] = df['ward'].replace(wp_in_ward)\n",
    "\n",
    "df.drop(['subvillage', 'lga', 'ward'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(include = ['object']).columns.tolist()\n",
    "# Any feature values with fewer than 50 rows would be turned into a 'other'\n",
    "for feature in df[categoricals]:\n",
    "    # Determine which feature values to keep\n",
    "    remove = df[feature].value_counts()[df[feature].value_counts() < 50].index.tolist()\n",
    "    #print(remove)\n",
    "    #to_keep = train[feature].value_counts()[train[feature].value_counts() > 50].index.tolist()\n",
    "    \n",
    "    # Turn those into NANs (using a copy, to prevent warnings)\n",
    "    feature_copy = df[feature].copy()\n",
    "    #feature_copy[~feature_copy.isin(to_keep)] = np.nan\n",
    "    feature_copy[feature_copy.isin(remove)] = np.nan\n",
    "    #print(feature_copy.isnull().sum())\n",
    "    df[feature] = feature_copy\n",
    "# Fix all NANs\n",
    "df[categoricals] = df[categoricals].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I checked that Tanzania has 31 region, so I will drop column 'region', beckause there is less values\n",
    "df.drop(['region', 'district_code'], 1, inplace=True)\n",
    "\n",
    "# extraction_type has very close values with extraction_type_group and extraction_type_class but extraction_type\n",
    "# has more values so I will \n",
    "# remove extraction_type_group, extraction_type_class\n",
    "\n",
    "df.drop('extraction_type_group', 1, inplace=True)\n",
    "df.drop('extraction_type_class', 1, inplace=True)\n",
    "\n",
    "# majority of 'management' looks the same so I will remove this columns and leave 'management_group' \n",
    "# and join small columns to 'other' \n",
    "df.management_group = df.management_group.apply(lambda x: 'other' if x != 'user-group' else x)\n",
    "\n",
    "# need to check shares in groups but nice and remove it\n",
    "# distribution in classes looks the same and this is not informative, will remove it\n",
    "df.drop(['management', 'management_group'], 1, inplace=True)\n",
    "\n",
    "# join pay to 1 group and others to another\n",
    "unpayable_types = ['never pay', 'other']\n",
    "df.payment = df.payment.apply(lambda x: 0 if x in unpayable_types else 1)\n",
    "df['payment']= df['payment'].astype('object')\n",
    "\n",
    "df.drop('payment_type', 1, inplace=True)\n",
    "# beckause payment shows the same info\n",
    "\n",
    "# quality_group looks very close to water_quality, so I will remove one\n",
    "df.drop(['water_quality'], 1, inplace=True)\n",
    "\n",
    "# quantity_group and quantity have the same info, so I will remove second one and join 'other' with 'dry' \n",
    "# beckause it small group\n",
    "df.drop(['quantity_group'], 1, inplace=True)\n",
    "\n",
    "#df.quantity = \n",
    "df.quantity.replace({'dry': 'other'}, inplace=True)\n",
    "\n",
    "# I will drop source_class and source_type becuase source is more detailed\n",
    "df.drop(['source_class', 'source_type'], 1, inplace=True)\n",
    "\n",
    "# waterpoint_type_group and waterpoint_type looks the same but  waterpoint_type more detailed\n",
    "df.drop('waterpoint_type_group', 1, inplace=True)\n",
    "\n",
    "# I will join 2 small classes with close distribution\n",
    "df.waterpoint_type.replace({'cattle trough':'improved spring'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.construction_year.fillna(0, inplace=True)\n",
    "df.construction_year = df.construction_year.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.construction_year = df.construction_year.replace(0, np.NaN)\n",
    "# add column that means that construction_year was filled with approximation\n",
    "df['approximated_construction_year'] = df['construction_year'].apply(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "replacements = df.groupby(['funder', 'installer'])['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "replacements = df.groupby('installer')['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "replacements = df.groupby('funder')['construction_year'].transform('mean').round(0)\n",
    "df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "df.construction_year.fillna(df.construction_year.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lifetimes'] = df['date_recorded'].dt.year - df['construction_year']\n",
    "df['lifetimes'] = np.where(df['lifetimes'] < 0, 0, df['lifetimes'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date_recorded', 'construction_year'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('prepeared_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['wp_in_subvillage'] = df['wp_in_subvillage'].astype(int)\n",
    "df['payment']= df['payment'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prepeared_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                        float64\n",
       "funder                             object\n",
       "gps_height                          int64\n",
       "installer                          object\n",
       "basin                              object\n",
       "region_code                        object\n",
       "population                        float64\n",
       "public_meeting                     object\n",
       "scheme_management                  object\n",
       "permit                             object\n",
       "extraction_type                    object\n",
       "payment                             int64\n",
       "quality_group                      object\n",
       "quantity                           object\n",
       "source                             object\n",
       "waterpoint_type                    object\n",
       "status_group                       object\n",
       "missed_population                   int64\n",
       "approximated_amount_tsh             int64\n",
       "wrong_gps_height                    int64\n",
       "wp_in_subvillage                  float64\n",
       "wp_in_lga                           int64\n",
       "wp_in_ward                          int64\n",
       "approximated_construction_year      int64\n",
       "lifetimes                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ww cat features\n",
    "1. onehotencod\n",
    "give the same num of columns as dummy\n",
    "2. target_encoding\n",
    "LR: 0.669481 (0.006335)\n",
    "RF: 0.776119 (0.007765)\n",
    "3. dummy_encode\n",
    "LR: 0.746746 (0.006960)\n",
    "RF: 0.780567 (0.007248)\n",
    "4. drop unnecessury features\n",
    "selected -3\n",
    "LR: 0.730112 (0.007359)\n",
    "RF: 0.779788 (0.003643)\n",
    "ww numeric features\n",
    "1. normalize\n",
    "LR: 0.717146 (0.007618)\n",
    "RF: 0.781848 (0.005260)\n",
    "2. log\n",
    "LR: 0.719659 (0.006688)\n",
    "RF: 0.783557 (0.006206)\n",
    "3. minMax\n",
    "LR: 0.730891 (0.007700)\n",
    "RF: 0.784662 (0.005118)\n",
    "4. robust\n",
    "LR: 0.727825 (0.007459)\n",
    "RF: 0.773531 (0.004417)\n",
    "5. drop unnecessury\n",
    "ww models\n",
    "1. install xgboost or lightgbm\n",
    "2. install cat boost\n",
    "3. NN\n",
    "4. randomGridSearch for best model\n",
    "predict on test data and validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['payment']= df['payment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include = ['float64', 'int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical = ['amount_tsh', 'gps_height', 'population', 'wp_in_subvillage', 'wp_in_lga', 'wp_in_ward', 'lifetimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                        float64\n",
       "funder                             object\n",
       "gps_height                          int64\n",
       "installer                          object\n",
       "basin                              object\n",
       "region_code                        object\n",
       "population                        float64\n",
       "public_meeting                     object\n",
       "scheme_management                  object\n",
       "permit                             object\n",
       "extraction_type                    object\n",
       "payment                             int64\n",
       "quality_group                      object\n",
       "quantity                           object\n",
       "source                             object\n",
       "waterpoint_type                    object\n",
       "status_group                        int64\n",
       "missed_population                   int64\n",
       "approximated_amount_tsh             int64\n",
       "wrong_gps_height                    int64\n",
       "wp_in_subvillage                  float64\n",
       "wp_in_lga                           int64\n",
       "wp_in_ward                          int64\n",
       "approximated_construction_year      int64\n",
       "lifetimes                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'population',\n",
       " 'wp_in_subvillage',\n",
       " 'wp_in_lga',\n",
       " 'wp_in_ward',\n",
       " 'lifetimes']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df[numerical] = preprocessing.normalize(df[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status_group = df.status_group.replace(['functional', 'non functional', 'functional needs repair'], [2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df.status_group\n",
    "train = df.drop('status_group', 1)\n",
    "numerical = train.select_dtypes(include = ['float64', 'int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "train[numerical] = preprocessing.normalize(train[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# robost\n",
    "scaler = RobustScaler()\n",
    "nums_scaled = scaler.fit_transform(df[numerical])\n",
    "nums_scaled = pd.DataFrame(nums_scaled, columns=numerical)\n",
    "df[numerical] = nums_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[numerical].values)\n",
    "train[numerical] = scaler.transform(train[numerical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "train[numerical] = np.log(train[numerical].values)\n",
    "\n",
    "train[numerical] = train[numerical].replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = train.select_dtypes(exclude=['number']).nunique().sort_values().index.tolist()[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public_meeting',\n",
       " 'permit',\n",
       " 'quantity',\n",
       " 'waterpoint_type',\n",
       " 'quality_group',\n",
       " 'basin',\n",
       " 'source',\n",
       " 'scheme_management',\n",
       " 'extraction_type']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorial = train.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "categorial = train.select_dtypes(include = ['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 63)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dum = pd.get_dummies(train[cols_to_keep], dummy_na=False, prefix = cols_to_keep)\n",
    "train_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = pd.concat([train_dum, train[non_categorial]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = lgb.LGBMClassifier(objective = 'multiclass' , silent=False,\n",
    "                       num_leaves=90, n_estimators=20, max_depth=50, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=50,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20, n_jobs=-1, num_leaves=90, objective='multiclass',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=False,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] num_leaves=120, n_estimators=10, max_depth=50, learning_rate=0.1 \n",
      "[CV] num_leaves=120, n_estimators=10, max_depth=50, learning_rate=0.1 \n",
      "[CV] num_leaves=120, n_estimators=10, max_depth=50, learning_rate=0.1 \n",
      "[CV] num_leaves=120, n_estimators=20, max_depth=25, learning_rate=0.01 \n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"max_depth\": [25,50, 75],\n",
    "              \"learning_rate\" : [0.01,0.05,0.1],\n",
    "              \"num_leaves\": [10, 30,90,120],\n",
    "              \"n_estimators\": [5, 10, 20]\n",
    "             }\n",
    "grid_search = RandomizedSearchCV(lg, n_jobs=4, n_iter = 2, param_distributions=param_dist, cv = 3, \n",
    "                                 scoring=\"roc_auc\", verbose=3, )\n",
    "grid_search.fit(X_train,y_train)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3305785123966942"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.65      0.74      7458\n",
      "          1       0.73      0.18      0.28      1425\n",
      "          2       0.74      0.93      0.82     10719\n",
      "\n",
      "avg / total       0.78      0.77      0.75     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:4239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -1.0762851\ttotal: 462ms\tremaining: 7m 41s\n",
      "1:\tlearn: -1.0555408\ttotal: 958ms\tremaining: 7m 57s\n",
      "2:\tlearn: -1.0360800\ttotal: 1.4s\tremaining: 7m 44s\n",
      "3:\tlearn: -1.0183194\ttotal: 1.82s\tremaining: 7m 33s\n",
      "4:\tlearn: -1.0012297\ttotal: 2.28s\tremaining: 7m 32s\n",
      "5:\tlearn: -0.9851964\ttotal: 2.69s\tremaining: 7m 25s\n",
      "6:\tlearn: -0.9701619\ttotal: 3.12s\tremaining: 7m 21s\n",
      "7:\tlearn: -0.9572234\ttotal: 3.38s\tremaining: 6m 59s\n",
      "8:\tlearn: -0.9437762\ttotal: 3.82s\tremaining: 7m\n",
      "9:\tlearn: -0.9308641\ttotal: 4.35s\tremaining: 7m 10s\n",
      "10:\tlearn: -0.9189119\ttotal: 4.77s\tremaining: 7m 9s\n",
      "11:\tlearn: -0.9080130\ttotal: 5.2s\tremaining: 7m 7s\n",
      "12:\tlearn: -0.8968834\ttotal: 5.66s\tremaining: 7m 9s\n",
      "13:\tlearn: -0.8864320\ttotal: 6.09s\tremaining: 7m 9s\n",
      "14:\tlearn: -0.8771565\ttotal: 6.52s\tremaining: 7m 8s\n",
      "15:\tlearn: -0.8681724\ttotal: 6.97s\tremaining: 7m 8s\n",
      "16:\tlearn: -0.8592890\ttotal: 7.42s\tremaining: 7m 8s\n",
      "17:\tlearn: -0.8511714\ttotal: 7.84s\tremaining: 7m 7s\n",
      "18:\tlearn: -0.8430494\ttotal: 8.28s\tremaining: 7m 7s\n",
      "19:\tlearn: -0.8357914\ttotal: 8.69s\tremaining: 7m 5s\n",
      "20:\tlearn: -0.8287428\ttotal: 9.14s\tremaining: 7m 6s\n",
      "21:\tlearn: -0.8220211\ttotal: 9.55s\tremaining: 7m 4s\n",
      "22:\tlearn: -0.8154614\ttotal: 9.98s\tremaining: 7m 3s\n",
      "23:\tlearn: -0.8093923\ttotal: 10.4s\tremaining: 7m 4s\n",
      "24:\tlearn: -0.8036395\ttotal: 10.9s\tremaining: 7m 3s\n",
      "25:\tlearn: -0.7982516\ttotal: 11.3s\tremaining: 7m 3s\n",
      "26:\tlearn: -0.7926750\ttotal: 11.7s\tremaining: 7m 3s\n",
      "27:\tlearn: -0.7873682\ttotal: 12.2s\tremaining: 7m 2s\n",
      "28:\tlearn: -0.7822106\ttotal: 12.6s\tremaining: 7m 1s\n",
      "29:\tlearn: -0.7775484\ttotal: 13s\tremaining: 7m\n",
      "30:\tlearn: -0.7730346\ttotal: 13.4s\tremaining: 6m 59s\n",
      "31:\tlearn: -0.7683652\ttotal: 13.8s\tremaining: 6m 58s\n",
      "32:\tlearn: -0.7641999\ttotal: 14.3s\tremaining: 6m 58s\n",
      "33:\tlearn: -0.7599789\ttotal: 14.7s\tremaining: 6m 58s\n",
      "34:\tlearn: -0.7561901\ttotal: 15.3s\tremaining: 7m 1s\n",
      "35:\tlearn: -0.7525415\ttotal: 16.1s\tremaining: 7m 9s\n",
      "36:\tlearn: -0.7489996\ttotal: 16.6s\tremaining: 7m 11s\n",
      "37:\tlearn: -0.7455257\ttotal: 17.1s\tremaining: 7m 11s\n",
      "38:\tlearn: -0.7422235\ttotal: 17.7s\tremaining: 7m 16s\n",
      "39:\tlearn: -0.7389665\ttotal: 18.6s\tremaining: 7m 26s\n",
      "40:\tlearn: -0.7360804\ttotal: 19.8s\tremaining: 7m 42s\n",
      "41:\tlearn: -0.7330942\ttotal: 20.8s\tremaining: 7m 53s\n",
      "42:\tlearn: -0.7302596\ttotal: 22.4s\tremaining: 8m 19s\n",
      "43:\tlearn: -0.7275125\ttotal: 23.7s\tremaining: 8m 34s\n",
      "44:\tlearn: -0.7251567\ttotal: 24.6s\tremaining: 8m 41s\n",
      "45:\tlearn: -0.7223936\ttotal: 26.2s\tremaining: 9m 2s\n",
      "46:\tlearn: -0.7197312\ttotal: 29.2s\tremaining: 9m 51s\n",
      "47:\tlearn: -0.7174550\ttotal: 33.9s\tremaining: 11m 13s\n",
      "48:\tlearn: -0.7151912\ttotal: 36.6s\tremaining: 11m 50s\n",
      "49:\tlearn: -0.7130566\ttotal: 38.5s\tremaining: 12m 12s\n",
      "50:\tlearn: -0.7107183\ttotal: 40s\tremaining: 12m 23s\n",
      "51:\tlearn: -0.7086008\ttotal: 40.7s\tremaining: 12m 21s\n",
      "52:\tlearn: -0.7063743\ttotal: 41.2s\tremaining: 12m 15s\n",
      "53:\tlearn: -0.7044073\ttotal: 41.7s\tremaining: 12m 10s\n",
      "54:\tlearn: -0.7026299\ttotal: 42.5s\tremaining: 12m 10s\n",
      "55:\tlearn: -0.7007923\ttotal: 43.4s\tremaining: 12m 11s\n",
      "56:\tlearn: -0.6990828\ttotal: 44.1s\tremaining: 12m 8s\n",
      "57:\tlearn: -0.6971048\ttotal: 44.6s\tremaining: 12m 3s\n",
      "58:\tlearn: -0.6955105\ttotal: 45.1s\tremaining: 11m 59s\n",
      "59:\tlearn: -0.6937934\ttotal: 45.6s\tremaining: 11m 55s\n",
      "60:\tlearn: -0.6922626\ttotal: 46.1s\tremaining: 11m 50s\n",
      "61:\tlearn: -0.6907610\ttotal: 46.7s\tremaining: 11m 46s\n",
      "62:\tlearn: -0.6892460\ttotal: 47.4s\tremaining: 11m 45s\n",
      "63:\tlearn: -0.6876647\ttotal: 48.3s\tremaining: 11m 46s\n",
      "64:\tlearn: -0.6864283\ttotal: 48.9s\tremaining: 11m 43s\n",
      "65:\tlearn: -0.6850096\ttotal: 49.7s\tremaining: 11m 43s\n",
      "66:\tlearn: -0.6834108\ttotal: 50.2s\tremaining: 11m 38s\n",
      "67:\tlearn: -0.6817108\ttotal: 50.6s\tremaining: 11m 33s\n",
      "68:\tlearn: -0.6801655\ttotal: 51.2s\tremaining: 11m 31s\n",
      "69:\tlearn: -0.6784687\ttotal: 51.9s\tremaining: 11m 29s\n",
      "70:\tlearn: -0.6769462\ttotal: 52.4s\tremaining: 11m 25s\n",
      "71:\tlearn: -0.6755483\ttotal: 53s\tremaining: 11m 22s\n",
      "72:\tlearn: -0.6742562\ttotal: 53.7s\tremaining: 11m 21s\n",
      "73:\tlearn: -0.6728790\ttotal: 54.3s\tremaining: 11m 18s\n",
      "74:\tlearn: -0.6718705\ttotal: 55s\tremaining: 11m 18s\n",
      "75:\tlearn: -0.6705162\ttotal: 55.7s\tremaining: 11m 16s\n",
      "76:\tlearn: -0.6692426\ttotal: 56.2s\tremaining: 11m 13s\n",
      "77:\tlearn: -0.6683415\ttotal: 58.8s\tremaining: 11m 35s\n",
      "78:\tlearn: -0.6670829\ttotal: 59.9s\tremaining: 11m 38s\n",
      "79:\tlearn: -0.6656721\ttotal: 1m 1s\tremaining: 11m 50s\n",
      "80:\tlearn: -0.6645341\ttotal: 1m 4s\tremaining: 12m 7s\n",
      "81:\tlearn: -0.6631613\ttotal: 1m 6s\tremaining: 12m 20s\n",
      "82:\tlearn: -0.6622001\ttotal: 1m 7s\tremaining: 12m 20s\n",
      "83:\tlearn: -0.6609399\ttotal: 1m 7s\tremaining: 12m 21s\n",
      "84:\tlearn: -0.6601178\ttotal: 1m 8s\tremaining: 12m 17s\n",
      "85:\tlearn: -0.6592751\ttotal: 1m 9s\tremaining: 12m 13s\n",
      "86:\tlearn: -0.6585065\ttotal: 1m 10s\tremaining: 12m 17s\n",
      "87:\tlearn: -0.6576001\ttotal: 1m 11s\tremaining: 12m 18s\n",
      "88:\tlearn: -0.6565800\ttotal: 1m 11s\tremaining: 12m 15s\n",
      "89:\tlearn: -0.6559544\ttotal: 1m 12s\tremaining: 12m 10s\n",
      "90:\tlearn: -0.6550202\ttotal: 1m 13s\tremaining: 12m 9s\n",
      "91:\tlearn: -0.6538682\ttotal: 1m 13s\tremaining: 12m 6s\n",
      "92:\tlearn: -0.6532575\ttotal: 1m 14s\tremaining: 12m 1s\n",
      "93:\tlearn: -0.6523114\ttotal: 1m 14s\tremaining: 11m 58s\n",
      "94:\tlearn: -0.6516158\ttotal: 1m 14s\tremaining: 11m 54s\n",
      "95:\tlearn: -0.6506768\ttotal: 1m 15s\tremaining: 11m 50s\n",
      "96:\tlearn: -0.6498878\ttotal: 1m 15s\tremaining: 11m 46s\n",
      "97:\tlearn: -0.6488813\ttotal: 1m 16s\tremaining: 11m 43s\n",
      "98:\tlearn: -0.6482966\ttotal: 1m 16s\tremaining: 11m 39s\n",
      "99:\tlearn: -0.6473866\ttotal: 1m 17s\tremaining: 11m 35s\n",
      "100:\tlearn: -0.6464206\ttotal: 1m 17s\tremaining: 11m 32s\n",
      "101:\tlearn: -0.6456777\ttotal: 1m 18s\tremaining: 11m 29s\n",
      "102:\tlearn: -0.6450173\ttotal: 1m 18s\tremaining: 11m 26s\n",
      "103:\tlearn: -0.6441699\ttotal: 1m 19s\tremaining: 11m 22s\n",
      "104:\tlearn: -0.6434231\ttotal: 1m 20s\tremaining: 11m 23s\n",
      "105:\tlearn: -0.6424397\ttotal: 1m 20s\tremaining: 11m 20s\n",
      "106:\tlearn: -0.6416825\ttotal: 1m 21s\tremaining: 11m 18s\n",
      "107:\tlearn: -0.6411545\ttotal: 1m 21s\tremaining: 11m 16s\n",
      "108:\tlearn: -0.6405679\ttotal: 1m 22s\tremaining: 11m 13s\n",
      "109:\tlearn: -0.6400844\ttotal: 1m 22s\tremaining: 11m 9s\n",
      "110:\tlearn: -0.6394310\ttotal: 1m 23s\tremaining: 11m 7s\n",
      "111:\tlearn: -0.6388066\ttotal: 1m 23s\tremaining: 11m 4s\n",
      "112:\tlearn: -0.6382634\ttotal: 1m 24s\tremaining: 11m 2s\n",
      "113:\tlearn: -0.6376224\ttotal: 1m 25s\tremaining: 11m 8s\n",
      "114:\tlearn: -0.6372129\ttotal: 1m 27s\tremaining: 11m 13s\n",
      "115:\tlearn: -0.6364995\ttotal: 1m 28s\tremaining: 11m 15s\n",
      "116:\tlearn: -0.6358192\ttotal: 1m 30s\tremaining: 11m 19s\n",
      "117:\tlearn: -0.6351070\ttotal: 1m 31s\tremaining: 11m 22s\n",
      "118:\tlearn: -0.6344040\ttotal: 1m 31s\tremaining: 11m 20s\n",
      "119:\tlearn: -0.6339810\ttotal: 1m 32s\tremaining: 11m 20s\n",
      "120:\tlearn: -0.6331731\ttotal: 1m 33s\tremaining: 11m 18s\n",
      "121:\tlearn: -0.6327763\ttotal: 1m 34s\tremaining: 11m 17s\n",
      "122:\tlearn: -0.6322943\ttotal: 1m 34s\tremaining: 11m 15s\n",
      "123:\tlearn: -0.6316632\ttotal: 1m 35s\tremaining: 11m 14s\n",
      "124:\tlearn: -0.6308615\ttotal: 1m 36s\tremaining: 11m 12s\n",
      "125:\tlearn: -0.6300905\ttotal: 1m 36s\tremaining: 11m 9s\n",
      "126:\tlearn: -0.6293257\ttotal: 1m 37s\tremaining: 11m 9s\n",
      "127:\tlearn: -0.6286852\ttotal: 1m 37s\tremaining: 11m 6s\n",
      "128:\tlearn: -0.6281032\ttotal: 1m 38s\tremaining: 11m 4s\n",
      "129:\tlearn: -0.6274299\ttotal: 1m 39s\tremaining: 11m 3s\n",
      "130:\tlearn: -0.6269155\ttotal: 1m 39s\tremaining: 11m\n",
      "131:\tlearn: -0.6264141\ttotal: 1m 40s\tremaining: 11m\n",
      "132:\tlearn: -0.6256939\ttotal: 1m 41s\tremaining: 10m 59s\n",
      "133:\tlearn: -0.6251912\ttotal: 1m 41s\tremaining: 10m 57s\n",
      "134:\tlearn: -0.6245924\ttotal: 1m 42s\tremaining: 10m 54s\n",
      "135:\tlearn: -0.6239192\ttotal: 1m 42s\tremaining: 10m 51s\n",
      "136:\tlearn: -0.6234505\ttotal: 1m 43s\tremaining: 10m 49s\n",
      "137:\tlearn: -0.6229050\ttotal: 1m 43s\tremaining: 10m 47s\n",
      "138:\tlearn: -0.6221779\ttotal: 1m 44s\tremaining: 10m 44s\n",
      "139:\tlearn: -0.6217664\ttotal: 1m 44s\tremaining: 10m 41s\n",
      "140:\tlearn: -0.6212336\ttotal: 1m 44s\tremaining: 10m 39s\n",
      "141:\tlearn: -0.6207849\ttotal: 1m 45s\tremaining: 10m 37s\n",
      "142:\tlearn: -0.6201759\ttotal: 1m 46s\tremaining: 10m 35s\n",
      "143:\tlearn: -0.6196521\ttotal: 1m 46s\tremaining: 10m 34s\n",
      "144:\tlearn: -0.6190730\ttotal: 1m 47s\tremaining: 10m 36s\n",
      "145:\tlearn: -0.6185920\ttotal: 1m 49s\tremaining: 10m 38s\n",
      "146:\tlearn: -0.6182618\ttotal: 1m 50s\tremaining: 10m 39s\n",
      "147:\tlearn: -0.6178224\ttotal: 1m 50s\tremaining: 10m 37s\n",
      "148:\tlearn: -0.6173615\ttotal: 1m 51s\tremaining: 10m 35s\n",
      "149:\tlearn: -0.6171247\ttotal: 1m 51s\tremaining: 10m 32s\n",
      "150:\tlearn: -0.6167071\ttotal: 1m 52s\tremaining: 10m 30s\n",
      "151:\tlearn: -0.6163704\ttotal: 1m 52s\tremaining: 10m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152:\tlearn: -0.6158887\ttotal: 1m 53s\tremaining: 10m 26s\n",
      "153:\tlearn: -0.6156517\ttotal: 1m 53s\tremaining: 10m 24s\n",
      "154:\tlearn: -0.6152305\ttotal: 1m 54s\tremaining: 10m 21s\n",
      "155:\tlearn: -0.6147315\ttotal: 1m 54s\tremaining: 10m 19s\n",
      "156:\tlearn: -0.6144987\ttotal: 1m 54s\tremaining: 10m 16s\n",
      "157:\tlearn: -0.6141228\ttotal: 1m 55s\tremaining: 10m 14s\n",
      "158:\tlearn: -0.6136611\ttotal: 1m 55s\tremaining: 10m 12s\n",
      "159:\tlearn: -0.6133125\ttotal: 1m 56s\tremaining: 10m 11s\n",
      "160:\tlearn: -0.6130662\ttotal: 1m 57s\tremaining: 10m 10s\n",
      "161:\tlearn: -0.6127852\ttotal: 1m 57s\tremaining: 10m 8s\n",
      "162:\tlearn: -0.6124820\ttotal: 1m 58s\tremaining: 10m 6s\n",
      "163:\tlearn: -0.6120611\ttotal: 1m 58s\tremaining: 10m 4s\n",
      "164:\tlearn: -0.6120209\ttotal: 1m 58s\tremaining: 10m\n",
      "165:\tlearn: -0.6115677\ttotal: 1m 59s\tremaining: 9m 58s\n",
      "166:\tlearn: -0.6110743\ttotal: 1m 59s\tremaining: 9m 56s\n",
      "167:\tlearn: -0.6108359\ttotal: 2m\tremaining: 9m 54s\n",
      "168:\tlearn: -0.6104463\ttotal: 2m\tremaining: 9m 52s\n",
      "169:\tlearn: -0.6101532\ttotal: 2m\tremaining: 9m 50s\n",
      "170:\tlearn: -0.6097474\ttotal: 2m 1s\tremaining: 9m 48s\n",
      "171:\tlearn: -0.6094529\ttotal: 2m 2s\tremaining: 9m 47s\n",
      "172:\tlearn: -0.6091775\ttotal: 2m 2s\tremaining: 9m 46s\n",
      "173:\tlearn: -0.6087337\ttotal: 2m 3s\tremaining: 9m 44s\n",
      "174:\tlearn: -0.6084678\ttotal: 2m 3s\tremaining: 9m 43s\n",
      "175:\tlearn: -0.6080739\ttotal: 2m 4s\tremaining: 9m 43s\n",
      "176:\tlearn: -0.6078544\ttotal: 2m 5s\tremaining: 9m 41s\n",
      "177:\tlearn: -0.6076994\ttotal: 2m 5s\tremaining: 9m 41s\n",
      "178:\tlearn: -0.6075668\ttotal: 2m 6s\tremaining: 9m 39s\n",
      "179:\tlearn: -0.6073555\ttotal: 2m 6s\tremaining: 9m 38s\n",
      "180:\tlearn: -0.6070976\ttotal: 2m 7s\tremaining: 9m 36s\n",
      "181:\tlearn: -0.6066319\ttotal: 2m 7s\tremaining: 9m 34s\n",
      "182:\tlearn: -0.6061822\ttotal: 2m 8s\tremaining: 9m 32s\n",
      "183:\tlearn: -0.6057919\ttotal: 2m 8s\tremaining: 9m 31s\n",
      "184:\tlearn: -0.6054519\ttotal: 2m 9s\tremaining: 9m 29s\n",
      "185:\tlearn: -0.6049583\ttotal: 2m 9s\tremaining: 9m 27s\n",
      "186:\tlearn: -0.6049393\ttotal: 2m 9s\tremaining: 9m 24s\n",
      "187:\tlearn: -0.6044887\ttotal: 2m 10s\tremaining: 9m 23s\n",
      "188:\tlearn: -0.6043051\ttotal: 2m 11s\tremaining: 9m 22s\n",
      "189:\tlearn: -0.6041280\ttotal: 2m 11s\tremaining: 9m 22s\n",
      "190:\tlearn: -0.6039453\ttotal: 2m 12s\tremaining: 9m 22s\n",
      "191:\tlearn: -0.6036565\ttotal: 2m 13s\tremaining: 9m 20s\n",
      "192:\tlearn: -0.6033332\ttotal: 2m 13s\tremaining: 9m 19s\n",
      "193:\tlearn: -0.6029760\ttotal: 2m 14s\tremaining: 9m 19s\n",
      "194:\tlearn: -0.6027563\ttotal: 2m 15s\tremaining: 9m 17s\n",
      "195:\tlearn: -0.6024320\ttotal: 2m 15s\tremaining: 9m 16s\n",
      "196:\tlearn: -0.6021436\ttotal: 2m 16s\tremaining: 9m 14s\n",
      "197:\tlearn: -0.6018992\ttotal: 2m 16s\tremaining: 9m 13s\n",
      "198:\tlearn: -0.6014926\ttotal: 2m 17s\tremaining: 9m 13s\n",
      "199:\tlearn: -0.6011945\ttotal: 2m 18s\tremaining: 9m 13s\n",
      "200:\tlearn: -0.6009281\ttotal: 2m 19s\tremaining: 9m 12s\n",
      "201:\tlearn: -0.6006519\ttotal: 2m 19s\tremaining: 9m 12s\n",
      "202:\tlearn: -0.6003940\ttotal: 2m 20s\tremaining: 9m 11s\n",
      "203:\tlearn: -0.5999982\ttotal: 2m 21s\tremaining: 9m 11s\n",
      "204:\tlearn: -0.5995663\ttotal: 2m 21s\tremaining: 9m 9s\n",
      "205:\tlearn: -0.5994014\ttotal: 2m 22s\tremaining: 9m 11s\n",
      "206:\tlearn: -0.5990696\ttotal: 2m 23s\tremaining: 9m 10s\n",
      "207:\tlearn: -0.5987068\ttotal: 2m 24s\tremaining: 9m 9s\n",
      "208:\tlearn: -0.5984676\ttotal: 2m 24s\tremaining: 9m 8s\n",
      "209:\tlearn: -0.5983178\ttotal: 2m 25s\tremaining: 9m 6s\n",
      "210:\tlearn: -0.5979093\ttotal: 2m 26s\tremaining: 9m 9s\n",
      "211:\tlearn: -0.5975290\ttotal: 2m 28s\tremaining: 9m 10s\n",
      "212:\tlearn: -0.5971255\ttotal: 2m 29s\tremaining: 9m 11s\n",
      "213:\tlearn: -0.5967321\ttotal: 2m 30s\tremaining: 9m 11s\n",
      "214:\tlearn: -0.5965563\ttotal: 2m 30s\tremaining: 9m 9s\n",
      "215:\tlearn: -0.5963332\ttotal: 2m 31s\tremaining: 9m 9s\n",
      "216:\tlearn: -0.5961497\ttotal: 2m 32s\tremaining: 9m 9s\n",
      "217:\tlearn: -0.5959342\ttotal: 2m 32s\tremaining: 9m 8s\n",
      "218:\tlearn: -0.5955982\ttotal: 2m 33s\tremaining: 9m 7s\n",
      "219:\tlearn: -0.5954043\ttotal: 2m 34s\tremaining: 9m 6s\n",
      "220:\tlearn: -0.5950805\ttotal: 2m 35s\tremaining: 9m 8s\n",
      "221:\tlearn: -0.5949296\ttotal: 2m 37s\tremaining: 9m 13s\n",
      "222:\tlearn: -0.5949106\ttotal: 2m 38s\tremaining: 9m 12s\n",
      "223:\tlearn: -0.5947905\ttotal: 2m 39s\tremaining: 9m 11s\n",
      "224:\tlearn: -0.5946720\ttotal: 2m 39s\tremaining: 9m 10s\n",
      "225:\tlearn: -0.5943380\ttotal: 2m 40s\tremaining: 9m 8s\n",
      "226:\tlearn: -0.5942198\ttotal: 2m 40s\tremaining: 9m 7s\n",
      "227:\tlearn: -0.5939375\ttotal: 2m 41s\tremaining: 9m 6s\n",
      "228:\tlearn: -0.5937660\ttotal: 2m 42s\tremaining: 9m 5s\n",
      "229:\tlearn: -0.5933070\ttotal: 2m 42s\tremaining: 9m 5s\n",
      "230:\tlearn: -0.5929303\ttotal: 2m 43s\tremaining: 9m 4s\n",
      "231:\tlearn: -0.5929008\ttotal: 2m 43s\tremaining: 9m 2s\n",
      "232:\tlearn: -0.5926923\ttotal: 2m 45s\tremaining: 9m 5s\n",
      "233:\tlearn: -0.5925067\ttotal: 2m 47s\tremaining: 9m 7s\n",
      "234:\tlearn: -0.5920881\ttotal: 2m 48s\tremaining: 9m 9s\n",
      "235:\tlearn: -0.5919245\ttotal: 2m 50s\tremaining: 9m 11s\n",
      "236:\tlearn: -0.5917595\ttotal: 2m 50s\tremaining: 9m 10s\n",
      "237:\tlearn: -0.5913352\ttotal: 2m 51s\tremaining: 9m 8s\n",
      "238:\tlearn: -0.5911573\ttotal: 2m 51s\tremaining: 9m 7s\n",
      "239:\tlearn: -0.5909971\ttotal: 2m 52s\tremaining: 9m 5s\n",
      "240:\tlearn: -0.5907201\ttotal: 2m 52s\tremaining: 9m 4s\n",
      "241:\tlearn: -0.5907116\ttotal: 2m 53s\tremaining: 9m 2s\n",
      "242:\tlearn: -0.5906301\ttotal: 2m 53s\tremaining: 9m 1s\n",
      "243:\tlearn: -0.5904838\ttotal: 2m 54s\tremaining: 9m\n",
      "244:\tlearn: -0.5903053\ttotal: 2m 54s\tremaining: 8m 58s\n",
      "245:\tlearn: -0.5900922\ttotal: 2m 55s\tremaining: 8m 57s\n",
      "246:\tlearn: -0.5897802\ttotal: 2m 55s\tremaining: 8m 55s\n",
      "247:\tlearn: -0.5896296\ttotal: 2m 56s\tremaining: 8m 55s\n",
      "248:\tlearn: -0.5892356\ttotal: 2m 57s\tremaining: 8m 56s\n",
      "249:\tlearn: -0.5891751\ttotal: 2m 58s\tremaining: 8m 55s\n",
      "250:\tlearn: -0.5890418\ttotal: 2m 59s\tremaining: 8m 55s\n",
      "251:\tlearn: -0.5889116\ttotal: 3m\tremaining: 8m 56s\n",
      "252:\tlearn: -0.5887006\ttotal: 3m 1s\tremaining: 8m 54s\n",
      "253:\tlearn: -0.5885621\ttotal: 3m 2s\tremaining: 8m 55s\n",
      "254:\tlearn: -0.5883858\ttotal: 3m 4s\tremaining: 8m 58s\n",
      "255:\tlearn: -0.5882328\ttotal: 3m 5s\tremaining: 8m 58s\n",
      "256:\tlearn: -0.5879611\ttotal: 3m 6s\tremaining: 8m 57s\n",
      "257:\tlearn: -0.5877849\ttotal: 3m 6s\tremaining: 8m 56s\n",
      "258:\tlearn: -0.5874464\ttotal: 3m 7s\tremaining: 8m 55s\n",
      "259:\tlearn: -0.5873614\ttotal: 3m 7s\tremaining: 8m 53s\n",
      "260:\tlearn: -0.5871608\ttotal: 3m 8s\tremaining: 8m 52s\n",
      "261:\tlearn: -0.5870291\ttotal: 3m 8s\tremaining: 8m 51s\n",
      "262:\tlearn: -0.5868080\ttotal: 3m 9s\tremaining: 8m 50s\n",
      "263:\tlearn: -0.5866976\ttotal: 3m 10s\tremaining: 8m 50s\n",
      "264:\tlearn: -0.5866861\ttotal: 3m 10s\tremaining: 8m 48s\n",
      "265:\tlearn: -0.5863675\ttotal: 3m 11s\tremaining: 8m 47s\n",
      "266:\tlearn: -0.5860992\ttotal: 3m 11s\tremaining: 8m 46s\n",
      "267:\tlearn: -0.5856990\ttotal: 3m 12s\tremaining: 8m 44s\n",
      "268:\tlearn: -0.5856741\ttotal: 3m 12s\tremaining: 8m 42s\n",
      "269:\tlearn: -0.5854811\ttotal: 3m 12s\tremaining: 8m 41s\n",
      "270:\tlearn: -0.5853573\ttotal: 3m 13s\tremaining: 8m 40s\n",
      "271:\tlearn: -0.5851936\ttotal: 3m 14s\tremaining: 8m 39s\n",
      "272:\tlearn: -0.5849622\ttotal: 3m 14s\tremaining: 8m 38s\n",
      "273:\tlearn: -0.5847355\ttotal: 3m 15s\tremaining: 8m 37s\n",
      "274:\tlearn: -0.5847153\ttotal: 3m 15s\tremaining: 8m 35s\n",
      "275:\tlearn: -0.5844774\ttotal: 3m 16s\tremaining: 8m 34s\n",
      "276:\tlearn: -0.5840535\ttotal: 3m 16s\tremaining: 8m 33s\n",
      "277:\tlearn: -0.5837952\ttotal: 3m 17s\tremaining: 8m 31s\n",
      "278:\tlearn: -0.5835687\ttotal: 3m 17s\tremaining: 8m 30s\n",
      "279:\tlearn: -0.5832782\ttotal: 3m 18s\tremaining: 8m 29s\n",
      "280:\tlearn: -0.5832679\ttotal: 3m 18s\tremaining: 8m 27s\n",
      "281:\tlearn: -0.5831300\ttotal: 3m 18s\tremaining: 8m 26s\n",
      "282:\tlearn: -0.5828234\ttotal: 3m 19s\tremaining: 8m 25s\n",
      "283:\tlearn: -0.5826834\ttotal: 3m 20s\tremaining: 8m 24s\n",
      "284:\tlearn: -0.5825023\ttotal: 3m 20s\tremaining: 8m 23s\n",
      "285:\tlearn: -0.5823913\ttotal: 3m 21s\tremaining: 8m 22s\n",
      "286:\tlearn: -0.5823219\ttotal: 3m 21s\tremaining: 8m 21s\n",
      "287:\tlearn: -0.5820788\ttotal: 3m 22s\tremaining: 8m 20s\n",
      "288:\tlearn: -0.5819183\ttotal: 3m 22s\tremaining: 8m 19s\n",
      "289:\tlearn: -0.5818298\ttotal: 3m 23s\tremaining: 8m 17s\n",
      "290:\tlearn: -0.5816704\ttotal: 3m 23s\tremaining: 8m 16s\n",
      "291:\tlearn: -0.5814966\ttotal: 3m 24s\tremaining: 8m 15s\n",
      "292:\tlearn: -0.5813763\ttotal: 3m 25s\tremaining: 8m 14s\n",
      "293:\tlearn: -0.5811909\ttotal: 3m 25s\tremaining: 8m 14s\n",
      "294:\tlearn: -0.5810804\ttotal: 3m 26s\tremaining: 8m 13s\n",
      "295:\tlearn: -0.5809742\ttotal: 3m 27s\tremaining: 8m 12s\n",
      "296:\tlearn: -0.5808483\ttotal: 3m 27s\tremaining: 8m 11s\n",
      "297:\tlearn: -0.5807819\ttotal: 3m 28s\tremaining: 8m 11s\n",
      "298:\tlearn: -0.5806299\ttotal: 3m 29s\tremaining: 8m 11s\n",
      "299:\tlearn: -0.5806201\ttotal: 3m 29s\tremaining: 8m 9s\n",
      "300:\tlearn: -0.5804717\ttotal: 3m 30s\tremaining: 8m 8s\n",
      "301:\tlearn: -0.5803432\ttotal: 3m 30s\tremaining: 8m 7s\n",
      "302:\tlearn: -0.5802433\ttotal: 3m 31s\tremaining: 8m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303:\tlearn: -0.5801265\ttotal: 3m 31s\tremaining: 8m 4s\n",
      "304:\tlearn: -0.5799652\ttotal: 3m 32s\tremaining: 8m 3s\n",
      "305:\tlearn: -0.5798710\ttotal: 3m 32s\tremaining: 8m 2s\n",
      "306:\tlearn: -0.5797888\ttotal: 3m 33s\tremaining: 8m 1s\n",
      "307:\tlearn: -0.5796259\ttotal: 3m 33s\tremaining: 8m\n",
      "308:\tlearn: -0.5793315\ttotal: 3m 34s\tremaining: 7m 59s\n",
      "309:\tlearn: -0.5792005\ttotal: 3m 35s\tremaining: 7m 59s\n",
      "310:\tlearn: -0.5790342\ttotal: 3m 35s\tremaining: 7m 58s\n",
      "311:\tlearn: -0.5788561\ttotal: 3m 36s\tremaining: 7m 57s\n",
      "312:\tlearn: -0.5785317\ttotal: 3m 36s\tremaining: 7m 56s\n",
      "313:\tlearn: -0.5783900\ttotal: 3m 37s\tremaining: 7m 55s\n",
      "314:\tlearn: -0.5782781\ttotal: 3m 37s\tremaining: 7m 53s\n",
      "315:\tlearn: -0.5781829\ttotal: 3m 38s\tremaining: 7m 52s\n",
      "316:\tlearn: -0.5781280\ttotal: 3m 39s\tremaining: 7m 51s\n",
      "317:\tlearn: -0.5778467\ttotal: 3m 39s\tremaining: 7m 50s\n",
      "318:\tlearn: -0.5776362\ttotal: 3m 40s\tremaining: 7m 49s\n",
      "319:\tlearn: -0.5773084\ttotal: 3m 40s\tremaining: 7m 48s\n",
      "320:\tlearn: -0.5770941\ttotal: 3m 41s\tremaining: 7m 47s\n",
      "321:\tlearn: -0.5768344\ttotal: 3m 41s\tremaining: 7m 47s\n",
      "322:\tlearn: -0.5766729\ttotal: 3m 42s\tremaining: 7m 46s\n",
      "323:\tlearn: -0.5765663\ttotal: 3m 43s\tremaining: 7m 45s\n",
      "324:\tlearn: -0.5764673\ttotal: 3m 43s\tremaining: 7m 44s\n",
      "325:\tlearn: -0.5762123\ttotal: 3m 44s\tremaining: 7m 43s\n",
      "326:\tlearn: -0.5760927\ttotal: 3m 45s\tremaining: 7m 43s\n",
      "327:\tlearn: -0.5759555\ttotal: 3m 45s\tremaining: 7m 42s\n",
      "328:\tlearn: -0.5756454\ttotal: 3m 46s\tremaining: 7m 41s\n",
      "329:\tlearn: -0.5755318\ttotal: 3m 46s\tremaining: 7m 40s\n",
      "330:\tlearn: -0.5754147\ttotal: 3m 47s\tremaining: 7m 40s\n",
      "331:\tlearn: -0.5753670\ttotal: 3m 48s\tremaining: 7m 39s\n",
      "332:\tlearn: -0.5752751\ttotal: 3m 48s\tremaining: 7m 38s\n",
      "333:\tlearn: -0.5751711\ttotal: 3m 49s\tremaining: 7m 38s\n",
      "334:\tlearn: -0.5749756\ttotal: 3m 50s\tremaining: 7m 37s\n",
      "335:\tlearn: -0.5748344\ttotal: 3m 50s\tremaining: 7m 36s\n",
      "336:\tlearn: -0.5747026\ttotal: 3m 51s\tremaining: 7m 35s\n",
      "337:\tlearn: -0.5745491\ttotal: 3m 52s\tremaining: 7m 34s\n",
      "338:\tlearn: -0.5744475\ttotal: 3m 52s\tremaining: 7m 34s\n",
      "339:\tlearn: -0.5742870\ttotal: 3m 53s\tremaining: 7m 33s\n",
      "340:\tlearn: -0.5741896\ttotal: 3m 53s\tremaining: 7m 32s\n",
      "341:\tlearn: -0.5740320\ttotal: 3m 54s\tremaining: 7m 30s\n",
      "342:\tlearn: -0.5737614\ttotal: 3m 55s\tremaining: 7m 30s\n",
      "343:\tlearn: -0.5736616\ttotal: 3m 55s\tremaining: 7m 29s\n",
      "344:\tlearn: -0.5735415\ttotal: 3m 56s\tremaining: 7m 29s\n",
      "345:\tlearn: -0.5734378\ttotal: 3m 57s\tremaining: 7m 28s\n",
      "346:\tlearn: -0.5731907\ttotal: 3m 57s\tremaining: 7m 27s\n",
      "347:\tlearn: -0.5730116\ttotal: 3m 58s\tremaining: 7m 26s\n",
      "348:\tlearn: -0.5729469\ttotal: 3m 59s\tremaining: 7m 26s\n",
      "349:\tlearn: -0.5727821\ttotal: 3m 59s\tremaining: 7m 25s\n",
      "350:\tlearn: -0.5725150\ttotal: 4m\tremaining: 7m 24s\n",
      "351:\tlearn: -0.5722161\ttotal: 4m\tremaining: 7m 23s\n",
      "352:\tlearn: -0.5721430\ttotal: 4m 1s\tremaining: 7m 22s\n",
      "353:\tlearn: -0.5720129\ttotal: 4m 1s\tremaining: 7m 21s\n",
      "354:\tlearn: -0.5719018\ttotal: 4m 2s\tremaining: 7m 20s\n",
      "355:\tlearn: -0.5716774\ttotal: 4m 2s\tremaining: 7m 19s\n",
      "356:\tlearn: -0.5714292\ttotal: 4m 3s\tremaining: 7m 18s\n",
      "357:\tlearn: -0.5712789\ttotal: 4m 3s\tremaining: 7m 17s\n",
      "358:\tlearn: -0.5711361\ttotal: 4m 4s\tremaining: 7m 16s\n",
      "359:\tlearn: -0.5710225\ttotal: 4m 5s\tremaining: 7m 15s\n",
      "360:\tlearn: -0.5710225\ttotal: 4m 5s\tremaining: 7m 14s\n",
      "361:\tlearn: -0.5709048\ttotal: 4m 5s\tremaining: 7m 13s\n",
      "362:\tlearn: -0.5707639\ttotal: 4m 6s\tremaining: 7m 12s\n",
      "363:\tlearn: -0.5706189\ttotal: 4m 6s\tremaining: 7m 11s\n",
      "364:\tlearn: -0.5705219\ttotal: 4m 7s\tremaining: 7m 10s\n",
      "365:\tlearn: -0.5703986\ttotal: 4m 8s\tremaining: 7m 9s\n",
      "366:\tlearn: -0.5702861\ttotal: 4m 8s\tremaining: 7m 9s\n",
      "367:\tlearn: -0.5700920\ttotal: 4m 9s\tremaining: 7m 8s\n",
      "368:\tlearn: -0.5700447\ttotal: 4m 10s\tremaining: 7m 8s\n",
      "369:\tlearn: -0.5697679\ttotal: 4m 10s\tremaining: 7m 7s\n",
      "370:\tlearn: -0.5696150\ttotal: 4m 11s\tremaining: 7m 6s\n",
      "371:\tlearn: -0.5693425\ttotal: 4m 12s\tremaining: 7m 5s\n",
      "372:\tlearn: -0.5691898\ttotal: 4m 12s\tremaining: 7m 4s\n",
      "373:\tlearn: -0.5689327\ttotal: 4m 12s\tremaining: 7m 3s\n",
      "374:\tlearn: -0.5687411\ttotal: 4m 13s\tremaining: 7m 3s\n",
      "375:\tlearn: -0.5686620\ttotal: 4m 14s\tremaining: 7m 2s\n",
      "376:\tlearn: -0.5685241\ttotal: 4m 15s\tremaining: 7m 1s\n",
      "377:\tlearn: -0.5682861\ttotal: 4m 15s\tremaining: 7m 1s\n",
      "378:\tlearn: -0.5680774\ttotal: 4m 16s\tremaining: 7m\n",
      "379:\tlearn: -0.5678272\ttotal: 4m 16s\tremaining: 6m 59s\n",
      "380:\tlearn: -0.5677255\ttotal: 4m 17s\tremaining: 6m 58s\n",
      "381:\tlearn: -0.5676408\ttotal: 4m 18s\tremaining: 6m 57s\n",
      "382:\tlearn: -0.5674276\ttotal: 4m 18s\tremaining: 6m 56s\n",
      "383:\tlearn: -0.5672695\ttotal: 4m 19s\tremaining: 6m 55s\n",
      "384:\tlearn: -0.5670834\ttotal: 4m 19s\tremaining: 6m 54s\n",
      "385:\tlearn: -0.5668793\ttotal: 4m 20s\tremaining: 6m 53s\n",
      "386:\tlearn: -0.5666079\ttotal: 4m 20s\tremaining: 6m 53s\n",
      "387:\tlearn: -0.5664203\ttotal: 4m 21s\tremaining: 6m 52s\n",
      "388:\tlearn: -0.5663455\ttotal: 4m 21s\tremaining: 6m 51s\n",
      "389:\tlearn: -0.5661232\ttotal: 4m 22s\tremaining: 6m 50s\n",
      "390:\tlearn: -0.5659676\ttotal: 4m 23s\tremaining: 6m 50s\n",
      "391:\tlearn: -0.5658759\ttotal: 4m 24s\tremaining: 6m 49s\n",
      "392:\tlearn: -0.5656953\ttotal: 4m 24s\tremaining: 6m 49s\n",
      "393:\tlearn: -0.5655679\ttotal: 4m 25s\tremaining: 6m 48s\n",
      "394:\tlearn: -0.5653346\ttotal: 4m 26s\tremaining: 6m 47s\n",
      "395:\tlearn: -0.5652149\ttotal: 4m 26s\tremaining: 6m 46s\n",
      "396:\tlearn: -0.5652097\ttotal: 4m 26s\tremaining: 6m 45s\n",
      "397:\tlearn: -0.5650225\ttotal: 4m 27s\tremaining: 6m 44s\n",
      "398:\tlearn: -0.5648882\ttotal: 4m 28s\tremaining: 6m 43s\n",
      "399:\tlearn: -0.5647924\ttotal: 4m 28s\tremaining: 6m 43s\n",
      "400:\tlearn: -0.5646706\ttotal: 4m 29s\tremaining: 6m 42s\n",
      "401:\tlearn: -0.5645330\ttotal: 4m 30s\tremaining: 6m 41s\n",
      "402:\tlearn: -0.5643405\ttotal: 4m 30s\tremaining: 6m 41s\n",
      "403:\tlearn: -0.5641701\ttotal: 4m 31s\tremaining: 6m 40s\n",
      "404:\tlearn: -0.5640510\ttotal: 4m 32s\tremaining: 6m 40s\n",
      "405:\tlearn: -0.5639392\ttotal: 4m 33s\tremaining: 6m 39s\n",
      "406:\tlearn: -0.5637944\ttotal: 4m 34s\tremaining: 6m 39s\n",
      "407:\tlearn: -0.5636422\ttotal: 4m 34s\tremaining: 6m 38s\n",
      "408:\tlearn: -0.5634144\ttotal: 4m 35s\tremaining: 6m 37s\n",
      "409:\tlearn: -0.5632155\ttotal: 4m 35s\tremaining: 6m 36s\n",
      "410:\tlearn: -0.5631792\ttotal: 4m 35s\tremaining: 6m 35s\n",
      "411:\tlearn: -0.5630042\ttotal: 4m 36s\tremaining: 6m 34s\n",
      "412:\tlearn: -0.5628208\ttotal: 4m 36s\tremaining: 6m 33s\n",
      "413:\tlearn: -0.5627123\ttotal: 4m 37s\tremaining: 6m 32s\n",
      "414:\tlearn: -0.5625798\ttotal: 4m 37s\tremaining: 6m 31s\n",
      "415:\tlearn: -0.5623307\ttotal: 4m 38s\tremaining: 6m 30s\n",
      "416:\tlearn: -0.5620360\ttotal: 4m 38s\tremaining: 6m 29s\n",
      "417:\tlearn: -0.5618971\ttotal: 4m 39s\tremaining: 6m 28s\n",
      "418:\tlearn: -0.5618316\ttotal: 4m 39s\tremaining: 6m 27s\n",
      "419:\tlearn: -0.5617145\ttotal: 4m 40s\tremaining: 6m 27s\n",
      "420:\tlearn: -0.5616445\ttotal: 4m 41s\tremaining: 6m 26s\n",
      "421:\tlearn: -0.5615001\ttotal: 4m 42s\tremaining: 6m 26s\n",
      "422:\tlearn: -0.5614138\ttotal: 4m 42s\tremaining: 6m 25s\n",
      "423:\tlearn: -0.5613155\ttotal: 4m 43s\tremaining: 6m 25s\n",
      "424:\tlearn: -0.5610029\ttotal: 4m 43s\tremaining: 6m 24s\n",
      "425:\tlearn: -0.5608672\ttotal: 4m 45s\tremaining: 6m 24s\n",
      "426:\tlearn: -0.5607400\ttotal: 4m 46s\tremaining: 6m 24s\n",
      "427:\tlearn: -0.5605940\ttotal: 4m 47s\tremaining: 6m 24s\n",
      "428:\tlearn: -0.5605465\ttotal: 4m 48s\tremaining: 6m 23s\n",
      "429:\tlearn: -0.5604007\ttotal: 4m 48s\tremaining: 6m 22s\n",
      "430:\tlearn: -0.5602723\ttotal: 4m 49s\tremaining: 6m 21s\n",
      "431:\tlearn: -0.5600826\ttotal: 4m 49s\tremaining: 6m 20s\n",
      "432:\tlearn: -0.5599212\ttotal: 4m 50s\tremaining: 6m 19s\n",
      "433:\tlearn: -0.5598693\ttotal: 4m 50s\tremaining: 6m 19s\n",
      "434:\tlearn: -0.5597336\ttotal: 4m 51s\tremaining: 6m 18s\n",
      "435:\tlearn: -0.5596595\ttotal: 4m 51s\tremaining: 6m 17s\n",
      "436:\tlearn: -0.5594975\ttotal: 4m 52s\tremaining: 6m 16s\n",
      "437:\tlearn: -0.5593236\ttotal: 4m 52s\tremaining: 6m 15s\n",
      "438:\tlearn: -0.5590360\ttotal: 4m 52s\tremaining: 6m 14s\n",
      "439:\tlearn: -0.5589843\ttotal: 4m 53s\tremaining: 6m 13s\n",
      "440:\tlearn: -0.5587097\ttotal: 4m 53s\tremaining: 6m 12s\n",
      "441:\tlearn: -0.5586681\ttotal: 4m 54s\tremaining: 6m 11s\n",
      "442:\tlearn: -0.5584492\ttotal: 4m 54s\tremaining: 6m 10s\n",
      "443:\tlearn: -0.5583834\ttotal: 4m 55s\tremaining: 6m 9s\n",
      "444:\tlearn: -0.5583060\ttotal: 4m 55s\tremaining: 6m 8s\n",
      "445:\tlearn: -0.5582341\ttotal: 4m 56s\tremaining: 6m 7s\n",
      "446:\tlearn: -0.5581222\ttotal: 4m 56s\tremaining: 6m 6s\n",
      "447:\tlearn: -0.5579857\ttotal: 4m 56s\tremaining: 6m 5s\n",
      "448:\tlearn: -0.5577756\ttotal: 4m 57s\tremaining: 6m 4s\n",
      "449:\tlearn: -0.5576973\ttotal: 4m 57s\tremaining: 6m 4s\n",
      "450:\tlearn: -0.5575786\ttotal: 4m 58s\tremaining: 6m 3s\n",
      "451:\tlearn: -0.5574286\ttotal: 4m 58s\tremaining: 6m 2s\n",
      "452:\tlearn: -0.5572809\ttotal: 4m 59s\tremaining: 6m 1s\n",
      "453:\tlearn: -0.5571384\ttotal: 4m 59s\tremaining: 6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454:\tlearn: -0.5570198\ttotal: 5m\tremaining: 5m 59s\n",
      "455:\tlearn: -0.5569318\ttotal: 5m\tremaining: 5m 58s\n",
      "456:\tlearn: -0.5568340\ttotal: 5m\tremaining: 5m 57s\n",
      "457:\tlearn: -0.5567423\ttotal: 5m 1s\tremaining: 5m 56s\n",
      "458:\tlearn: -0.5566224\ttotal: 5m 1s\tremaining: 5m 55s\n",
      "459:\tlearn: -0.5564033\ttotal: 5m 2s\tremaining: 5m 54s\n",
      "460:\tlearn: -0.5562621\ttotal: 5m 2s\tremaining: 5m 53s\n",
      "461:\tlearn: -0.5561221\ttotal: 5m 3s\tremaining: 5m 53s\n",
      "462:\tlearn: -0.5560441\ttotal: 5m 3s\tremaining: 5m 52s\n",
      "463:\tlearn: -0.5559309\ttotal: 5m 4s\tremaining: 5m 51s\n",
      "464:\tlearn: -0.5558469\ttotal: 5m 6s\tremaining: 5m 52s\n",
      "465:\tlearn: -0.5557930\ttotal: 5m 8s\tremaining: 5m 53s\n",
      "466:\tlearn: -0.5556859\ttotal: 5m 9s\tremaining: 5m 52s\n",
      "467:\tlearn: -0.5555647\ttotal: 5m 9s\tremaining: 5m 52s\n",
      "468:\tlearn: -0.5554751\ttotal: 5m 10s\tremaining: 5m 51s\n",
      "469:\tlearn: -0.5553975\ttotal: 5m 11s\tremaining: 5m 51s\n",
      "470:\tlearn: -0.5552433\ttotal: 5m 12s\tremaining: 5m 50s\n",
      "471:\tlearn: -0.5551408\ttotal: 5m 12s\tremaining: 5m 49s\n",
      "472:\tlearn: -0.5549878\ttotal: 5m 13s\tremaining: 5m 49s\n",
      "473:\tlearn: -0.5549364\ttotal: 5m 14s\tremaining: 5m 48s\n",
      "474:\tlearn: -0.5548632\ttotal: 5m 14s\tremaining: 5m 48s\n",
      "475:\tlearn: -0.5547019\ttotal: 5m 15s\tremaining: 5m 47s\n",
      "476:\tlearn: -0.5546059\ttotal: 5m 15s\tremaining: 5m 46s\n",
      "477:\tlearn: -0.5545538\ttotal: 5m 16s\tremaining: 5m 45s\n",
      "478:\tlearn: -0.5544253\ttotal: 5m 17s\tremaining: 5m 44s\n",
      "479:\tlearn: -0.5542497\ttotal: 5m 17s\tremaining: 5m 44s\n",
      "480:\tlearn: -0.5541324\ttotal: 5m 18s\tremaining: 5m 43s\n",
      "481:\tlearn: -0.5540516\ttotal: 5m 19s\tremaining: 5m 43s\n",
      "482:\tlearn: -0.5539780\ttotal: 5m 19s\tremaining: 5m 42s\n",
      "483:\tlearn: -0.5538312\ttotal: 5m 20s\tremaining: 5m 41s\n",
      "484:\tlearn: -0.5537575\ttotal: 5m 20s\tremaining: 5m 40s\n",
      "485:\tlearn: -0.5536675\ttotal: 5m 21s\tremaining: 5m 39s\n",
      "486:\tlearn: -0.5534881\ttotal: 5m 21s\tremaining: 5m 39s\n",
      "487:\tlearn: -0.5534330\ttotal: 5m 22s\tremaining: 5m 38s\n",
      "488:\tlearn: -0.5532762\ttotal: 5m 23s\tremaining: 5m 37s\n",
      "489:\tlearn: -0.5532138\ttotal: 5m 23s\tremaining: 5m 37s\n",
      "490:\tlearn: -0.5531714\ttotal: 5m 24s\tremaining: 5m 36s\n",
      "491:\tlearn: -0.5530997\ttotal: 5m 25s\tremaining: 5m 35s\n",
      "492:\tlearn: -0.5529983\ttotal: 5m 25s\tremaining: 5m 34s\n",
      "493:\tlearn: -0.5528691\ttotal: 5m 26s\tremaining: 5m 34s\n",
      "494:\tlearn: -0.5527168\ttotal: 5m 26s\tremaining: 5m 33s\n",
      "495:\tlearn: -0.5526559\ttotal: 5m 27s\tremaining: 5m 32s\n",
      "496:\tlearn: -0.5525562\ttotal: 5m 27s\tremaining: 5m 31s\n",
      "497:\tlearn: -0.5524895\ttotal: 5m 28s\tremaining: 5m 31s\n",
      "498:\tlearn: -0.5524146\ttotal: 5m 29s\tremaining: 5m 30s\n",
      "499:\tlearn: -0.5523897\ttotal: 5m 29s\tremaining: 5m 29s\n",
      "500:\tlearn: -0.5523180\ttotal: 5m 30s\tremaining: 5m 29s\n",
      "501:\tlearn: -0.5522184\ttotal: 5m 30s\tremaining: 5m 28s\n",
      "502:\tlearn: -0.5520714\ttotal: 5m 31s\tremaining: 5m 27s\n",
      "503:\tlearn: -0.5520023\ttotal: 5m 32s\tremaining: 5m 26s\n",
      "504:\tlearn: -0.5518252\ttotal: 5m 32s\tremaining: 5m 26s\n",
      "505:\tlearn: -0.5517228\ttotal: 5m 33s\tremaining: 5m 25s\n",
      "506:\tlearn: -0.5516211\ttotal: 5m 33s\tremaining: 5m 24s\n",
      "507:\tlearn: -0.5515298\ttotal: 5m 34s\tremaining: 5m 23s\n",
      "508:\tlearn: -0.5514867\ttotal: 5m 35s\tremaining: 5m 23s\n",
      "509:\tlearn: -0.5513833\ttotal: 5m 35s\tremaining: 5m 22s\n",
      "510:\tlearn: -0.5513416\ttotal: 5m 36s\tremaining: 5m 21s\n",
      "511:\tlearn: -0.5512915\ttotal: 5m 36s\tremaining: 5m 21s\n",
      "512:\tlearn: -0.5512281\ttotal: 5m 37s\tremaining: 5m 20s\n",
      "513:\tlearn: -0.5510673\ttotal: 5m 38s\tremaining: 5m 19s\n",
      "514:\tlearn: -0.5509831\ttotal: 5m 39s\tremaining: 5m 19s\n",
      "515:\tlearn: -0.5508486\ttotal: 5m 39s\tremaining: 5m 18s\n",
      "516:\tlearn: -0.5507109\ttotal: 5m 40s\tremaining: 5m 17s\n",
      "517:\tlearn: -0.5506533\ttotal: 5m 40s\tremaining: 5m 16s\n",
      "518:\tlearn: -0.5505753\ttotal: 5m 41s\tremaining: 5m 16s\n",
      "519:\tlearn: -0.5504073\ttotal: 5m 41s\tremaining: 5m 15s\n",
      "520:\tlearn: -0.5503303\ttotal: 5m 42s\tremaining: 5m 14s\n",
      "521:\tlearn: -0.5502906\ttotal: 5m 42s\tremaining: 5m 14s\n",
      "522:\tlearn: -0.5501473\ttotal: 5m 43s\tremaining: 5m 13s\n",
      "523:\tlearn: -0.5500555\ttotal: 5m 44s\tremaining: 5m 12s\n",
      "524:\tlearn: -0.5499408\ttotal: 5m 44s\tremaining: 5m 11s\n",
      "525:\tlearn: -0.5497025\ttotal: 5m 45s\tremaining: 5m 10s\n",
      "526:\tlearn: -0.5495633\ttotal: 5m 45s\tremaining: 5m 10s\n",
      "527:\tlearn: -0.5494175\ttotal: 5m 46s\tremaining: 5m 9s\n",
      "528:\tlearn: -0.5492300\ttotal: 5m 46s\tremaining: 5m 8s\n",
      "529:\tlearn: -0.5490625\ttotal: 5m 47s\tremaining: 5m 7s\n",
      "530:\tlearn: -0.5490172\ttotal: 5m 47s\tremaining: 5m 7s\n",
      "531:\tlearn: -0.5488913\ttotal: 5m 48s\tremaining: 5m 6s\n",
      "532:\tlearn: -0.5487382\ttotal: 5m 49s\tremaining: 5m 5s\n",
      "533:\tlearn: -0.5486008\ttotal: 5m 49s\tremaining: 5m 5s\n",
      "534:\tlearn: -0.5485550\ttotal: 5m 50s\tremaining: 5m 4s\n",
      "535:\tlearn: -0.5483901\ttotal: 5m 51s\tremaining: 5m 3s\n",
      "536:\tlearn: -0.5483092\ttotal: 5m 51s\tremaining: 5m 3s\n",
      "537:\tlearn: -0.5481244\ttotal: 5m 52s\tremaining: 5m 2s\n",
      "538:\tlearn: -0.5480610\ttotal: 5m 52s\tremaining: 5m 1s\n",
      "539:\tlearn: -0.5479741\ttotal: 5m 53s\tremaining: 5m\n",
      "540:\tlearn: -0.5478999\ttotal: 5m 53s\tremaining: 5m\n",
      "541:\tlearn: -0.5478740\ttotal: 5m 54s\tremaining: 4m 59s\n",
      "542:\tlearn: -0.5477883\ttotal: 5m 55s\tremaining: 4m 58s\n",
      "543:\tlearn: -0.5477166\ttotal: 5m 56s\tremaining: 4m 58s\n",
      "544:\tlearn: -0.5475996\ttotal: 5m 58s\tremaining: 4m 59s\n",
      "545:\tlearn: -0.5474867\ttotal: 5m 59s\tremaining: 4m 58s\n",
      "546:\tlearn: -0.5474239\ttotal: 6m\tremaining: 4m 58s\n",
      "547:\tlearn: -0.5473633\ttotal: 6m\tremaining: 4m 57s\n",
      "548:\tlearn: -0.5472792\ttotal: 6m 1s\tremaining: 4m 57s\n",
      "549:\tlearn: -0.5471617\ttotal: 6m 2s\tremaining: 4m 56s\n",
      "550:\tlearn: -0.5471062\ttotal: 6m 2s\tremaining: 4m 55s\n",
      "551:\tlearn: -0.5469855\ttotal: 6m 3s\tremaining: 4m 54s\n",
      "552:\tlearn: -0.5469377\ttotal: 6m 3s\tremaining: 4m 54s\n",
      "553:\tlearn: -0.5468614\ttotal: 6m 4s\tremaining: 4m 53s\n",
      "554:\tlearn: -0.5468357\ttotal: 6m 5s\tremaining: 4m 53s\n",
      "555:\tlearn: -0.5467720\ttotal: 6m 6s\tremaining: 4m 52s\n",
      "556:\tlearn: -0.5467102\ttotal: 6m 6s\tremaining: 4m 51s\n",
      "557:\tlearn: -0.5465679\ttotal: 6m 7s\tremaining: 4m 51s\n",
      "558:\tlearn: -0.5464838\ttotal: 6m 7s\tremaining: 4m 50s\n",
      "559:\tlearn: -0.5463720\ttotal: 6m 8s\tremaining: 4m 49s\n",
      "560:\tlearn: -0.5462946\ttotal: 6m 8s\tremaining: 4m 48s\n",
      "561:\tlearn: -0.5462273\ttotal: 6m 9s\tremaining: 4m 47s\n",
      "562:\tlearn: -0.5461350\ttotal: 6m 9s\tremaining: 4m 46s\n",
      "563:\tlearn: -0.5460767\ttotal: 6m 10s\tremaining: 4m 46s\n",
      "564:\tlearn: -0.5460005\ttotal: 6m 10s\tremaining: 4m 45s\n",
      "565:\tlearn: -0.5458800\ttotal: 6m 10s\tremaining: 4m 44s\n",
      "566:\tlearn: -0.5458350\ttotal: 6m 11s\tremaining: 4m 43s\n",
      "567:\tlearn: -0.5457363\ttotal: 6m 11s\tremaining: 4m 42s\n",
      "568:\tlearn: -0.5456594\ttotal: 6m 12s\tremaining: 4m 42s\n",
      "569:\tlearn: -0.5455757\ttotal: 6m 12s\tremaining: 4m 41s\n",
      "570:\tlearn: -0.5454687\ttotal: 6m 13s\tremaining: 4m 40s\n",
      "571:\tlearn: -0.5454275\ttotal: 6m 13s\tremaining: 4m 39s\n",
      "572:\tlearn: -0.5453867\ttotal: 6m 14s\tremaining: 4m 38s\n",
      "573:\tlearn: -0.5453183\ttotal: 6m 14s\tremaining: 4m 37s\n",
      "574:\tlearn: -0.5452821\ttotal: 6m 15s\tremaining: 4m 37s\n",
      "575:\tlearn: -0.5452147\ttotal: 6m 15s\tremaining: 4m 36s\n",
      "576:\tlearn: -0.5451556\ttotal: 6m 15s\tremaining: 4m 35s\n",
      "577:\tlearn: -0.5450643\ttotal: 6m 16s\tremaining: 4m 34s\n",
      "578:\tlearn: -0.5449000\ttotal: 6m 16s\tremaining: 4m 33s\n",
      "579:\tlearn: -0.5448148\ttotal: 6m 17s\tremaining: 4m 33s\n",
      "580:\tlearn: -0.5447498\ttotal: 6m 17s\tremaining: 4m 32s\n",
      "581:\tlearn: -0.5446492\ttotal: 6m 18s\tremaining: 4m 31s\n",
      "582:\tlearn: -0.5444809\ttotal: 6m 18s\tremaining: 4m 30s\n",
      "583:\tlearn: -0.5444511\ttotal: 6m 18s\tremaining: 4m 29s\n",
      "584:\tlearn: -0.5444111\ttotal: 6m 19s\tremaining: 4m 29s\n",
      "585:\tlearn: -0.5443000\ttotal: 6m 19s\tremaining: 4m 28s\n",
      "586:\tlearn: -0.5442216\ttotal: 6m 20s\tremaining: 4m 27s\n",
      "587:\tlearn: -0.5442010\ttotal: 6m 20s\tremaining: 4m 26s\n",
      "588:\tlearn: -0.5441522\ttotal: 6m 21s\tremaining: 4m 25s\n",
      "589:\tlearn: -0.5440982\ttotal: 6m 21s\tremaining: 4m 25s\n",
      "590:\tlearn: -0.5440627\ttotal: 6m 21s\tremaining: 4m 24s\n",
      "591:\tlearn: -0.5439794\ttotal: 6m 22s\tremaining: 4m 23s\n",
      "592:\tlearn: -0.5438631\ttotal: 6m 22s\tremaining: 4m 22s\n",
      "593:\tlearn: -0.5437332\ttotal: 6m 23s\tremaining: 4m 21s\n",
      "594:\tlearn: -0.5436700\ttotal: 6m 23s\tremaining: 4m 21s\n",
      "595:\tlearn: -0.5435985\ttotal: 6m 24s\tremaining: 4m 20s\n",
      "596:\tlearn: -0.5435133\ttotal: 6m 24s\tremaining: 4m 19s\n",
      "597:\tlearn: -0.5434382\ttotal: 6m 25s\tremaining: 4m 18s\n",
      "598:\tlearn: -0.5433799\ttotal: 6m 25s\tremaining: 4m 18s\n",
      "599:\tlearn: -0.5432933\ttotal: 6m 25s\tremaining: 4m 17s\n",
      "600:\tlearn: -0.5432577\ttotal: 6m 26s\tremaining: 4m 16s\n",
      "601:\tlearn: -0.5432175\ttotal: 6m 26s\tremaining: 4m 15s\n",
      "602:\tlearn: -0.5431583\ttotal: 6m 27s\tremaining: 4m 15s\n",
      "603:\tlearn: -0.5431308\ttotal: 6m 28s\tremaining: 4m 14s\n",
      "604:\tlearn: -0.5430702\ttotal: 6m 28s\tremaining: 4m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605:\tlearn: -0.5429003\ttotal: 6m 29s\tremaining: 4m 13s\n",
      "606:\tlearn: -0.5428313\ttotal: 6m 29s\tremaining: 4m 12s\n",
      "607:\tlearn: -0.5427850\ttotal: 6m 30s\tremaining: 4m 11s\n",
      "608:\tlearn: -0.5426526\ttotal: 6m 30s\tremaining: 4m 10s\n",
      "609:\tlearn: -0.5425164\ttotal: 6m 31s\tremaining: 4m 10s\n",
      "610:\tlearn: -0.5424560\ttotal: 6m 33s\tremaining: 4m 10s\n",
      "611:\tlearn: -0.5424196\ttotal: 6m 33s\tremaining: 4m 9s\n",
      "612:\tlearn: -0.5423871\ttotal: 6m 34s\tremaining: 4m 9s\n",
      "613:\tlearn: -0.5422856\ttotal: 6m 35s\tremaining: 4m 8s\n",
      "614:\tlearn: -0.5421334\ttotal: 6m 36s\tremaining: 4m 7s\n",
      "615:\tlearn: -0.5420669\ttotal: 6m 36s\tremaining: 4m 7s\n",
      "616:\tlearn: -0.5419957\ttotal: 6m 37s\tremaining: 4m 6s\n",
      "617:\tlearn: -0.5419309\ttotal: 6m 37s\tremaining: 4m 5s\n",
      "618:\tlearn: -0.5418132\ttotal: 6m 38s\tremaining: 4m 4s\n",
      "619:\tlearn: -0.5417777\ttotal: 6m 38s\tremaining: 4m 4s\n",
      "620:\tlearn: -0.5416797\ttotal: 6m 39s\tremaining: 4m 3s\n",
      "621:\tlearn: -0.5416172\ttotal: 6m 39s\tremaining: 4m 2s\n",
      "622:\tlearn: -0.5415686\ttotal: 6m 40s\tremaining: 4m 2s\n",
      "623:\tlearn: -0.5414844\ttotal: 6m 40s\tremaining: 4m 1s\n",
      "624:\tlearn: -0.5414536\ttotal: 6m 41s\tremaining: 4m\n",
      "625:\tlearn: -0.5413802\ttotal: 6m 42s\tremaining: 4m\n",
      "626:\tlearn: -0.5412917\ttotal: 6m 43s\tremaining: 4m\n",
      "627:\tlearn: -0.5411747\ttotal: 6m 44s\tremaining: 3m 59s\n",
      "628:\tlearn: -0.5411337\ttotal: 6m 44s\tremaining: 3m 58s\n",
      "629:\tlearn: -0.5410846\ttotal: 6m 45s\tremaining: 3m 58s\n",
      "630:\tlearn: -0.5410265\ttotal: 6m 45s\tremaining: 3m 57s\n",
      "631:\tlearn: -0.5409341\ttotal: 6m 46s\tremaining: 3m 56s\n",
      "632:\tlearn: -0.5408560\ttotal: 6m 46s\tremaining: 3m 55s\n",
      "633:\tlearn: -0.5408039\ttotal: 6m 47s\tremaining: 3m 55s\n",
      "634:\tlearn: -0.5407662\ttotal: 6m 47s\tremaining: 3m 54s\n",
      "635:\tlearn: -0.5407060\ttotal: 6m 48s\tremaining: 3m 53s\n",
      "636:\tlearn: -0.5406829\ttotal: 6m 48s\tremaining: 3m 53s\n",
      "637:\tlearn: -0.5406264\ttotal: 6m 49s\tremaining: 3m 52s\n",
      "638:\tlearn: -0.5405588\ttotal: 6m 50s\tremaining: 3m 51s\n",
      "639:\tlearn: -0.5404534\ttotal: 6m 50s\tremaining: 3m 50s\n",
      "640:\tlearn: -0.5403925\ttotal: 6m 51s\tremaining: 3m 50s\n",
      "641:\tlearn: -0.5403625\ttotal: 6m 51s\tremaining: 3m 49s\n",
      "642:\tlearn: -0.5403406\ttotal: 6m 52s\tremaining: 3m 48s\n",
      "643:\tlearn: -0.5403159\ttotal: 6m 52s\tremaining: 3m 48s\n",
      "644:\tlearn: -0.5402816\ttotal: 6m 53s\tremaining: 3m 47s\n",
      "645:\tlearn: -0.5402443\ttotal: 6m 53s\tremaining: 3m 46s\n",
      "646:\tlearn: -0.5401256\ttotal: 6m 54s\tremaining: 3m 46s\n",
      "647:\tlearn: -0.5401074\ttotal: 6m 55s\tremaining: 3m 45s\n",
      "648:\tlearn: -0.5399995\ttotal: 6m 55s\tremaining: 3m 44s\n",
      "649:\tlearn: -0.5399543\ttotal: 6m 56s\tremaining: 3m 44s\n",
      "650:\tlearn: -0.5398705\ttotal: 6m 56s\tremaining: 3m 43s\n",
      "651:\tlearn: -0.5398127\ttotal: 6m 57s\tremaining: 3m 42s\n",
      "652:\tlearn: -0.5397741\ttotal: 6m 57s\tremaining: 3m 41s\n",
      "653:\tlearn: -0.5396829\ttotal: 6m 58s\tremaining: 3m 41s\n",
      "654:\tlearn: -0.5396320\ttotal: 6m 58s\tremaining: 3m 40s\n",
      "655:\tlearn: -0.5395759\ttotal: 6m 59s\tremaining: 3m 40s\n",
      "656:\tlearn: -0.5394607\ttotal: 7m\tremaining: 3m 39s\n",
      "657:\tlearn: -0.5393890\ttotal: 7m\tremaining: 3m 38s\n",
      "658:\tlearn: -0.5392711\ttotal: 7m 1s\tremaining: 3m 37s\n",
      "659:\tlearn: -0.5391449\ttotal: 7m 1s\tremaining: 3m 37s\n",
      "660:\tlearn: -0.5390839\ttotal: 7m 2s\tremaining: 3m 36s\n",
      "661:\tlearn: -0.5390714\ttotal: 7m 2s\tremaining: 3m 35s\n",
      "662:\tlearn: -0.5389853\ttotal: 7m 3s\tremaining: 3m 35s\n",
      "663:\tlearn: -0.5389480\ttotal: 7m 4s\tremaining: 3m 34s\n",
      "664:\tlearn: -0.5387915\ttotal: 7m 4s\tremaining: 3m 34s\n",
      "665:\tlearn: -0.5387283\ttotal: 7m 5s\tremaining: 3m 33s\n",
      "666:\tlearn: -0.5386699\ttotal: 7m 5s\tremaining: 3m 32s\n",
      "667:\tlearn: -0.5386006\ttotal: 7m 6s\tremaining: 3m 31s\n",
      "668:\tlearn: -0.5385623\ttotal: 7m 6s\tremaining: 3m 31s\n",
      "669:\tlearn: -0.5384571\ttotal: 7m 7s\tremaining: 3m 30s\n",
      "670:\tlearn: -0.5383551\ttotal: 7m 8s\tremaining: 3m 29s\n",
      "671:\tlearn: -0.5383203\ttotal: 7m 8s\tremaining: 3m 29s\n",
      "672:\tlearn: -0.5382849\ttotal: 7m 9s\tremaining: 3m 28s\n",
      "673:\tlearn: -0.5382121\ttotal: 7m 9s\tremaining: 3m 27s\n",
      "674:\tlearn: -0.5381164\ttotal: 7m 10s\tremaining: 3m 27s\n",
      "675:\tlearn: -0.5380427\ttotal: 7m 10s\tremaining: 3m 26s\n",
      "676:\tlearn: -0.5379171\ttotal: 7m 11s\tremaining: 3m 25s\n",
      "677:\tlearn: -0.5378560\ttotal: 7m 11s\tremaining: 3m 24s\n",
      "678:\tlearn: -0.5377935\ttotal: 7m 12s\tremaining: 3m 24s\n",
      "679:\tlearn: -0.5376627\ttotal: 7m 12s\tremaining: 3m 23s\n",
      "680:\tlearn: -0.5376229\ttotal: 7m 13s\tremaining: 3m 22s\n",
      "681:\tlearn: -0.5375453\ttotal: 7m 13s\tremaining: 3m 22s\n",
      "682:\tlearn: -0.5374937\ttotal: 7m 14s\tremaining: 3m 21s\n",
      "683:\tlearn: -0.5373735\ttotal: 7m 14s\tremaining: 3m 20s\n",
      "684:\tlearn: -0.5373254\ttotal: 7m 14s\tremaining: 3m 20s\n",
      "685:\tlearn: -0.5372795\ttotal: 7m 15s\tremaining: 3m 19s\n",
      "686:\tlearn: -0.5372234\ttotal: 7m 16s\tremaining: 3m 18s\n",
      "687:\tlearn: -0.5371509\ttotal: 7m 16s\tremaining: 3m 17s\n",
      "688:\tlearn: -0.5370834\ttotal: 7m 17s\tremaining: 3m 17s\n",
      "689:\tlearn: -0.5370459\ttotal: 7m 17s\tremaining: 3m 16s\n",
      "690:\tlearn: -0.5369993\ttotal: 7m 18s\tremaining: 3m 15s\n",
      "691:\tlearn: -0.5369431\ttotal: 7m 18s\tremaining: 3m 15s\n",
      "692:\tlearn: -0.5368166\ttotal: 7m 19s\tremaining: 3m 14s\n",
      "693:\tlearn: -0.5367498\ttotal: 7m 19s\tremaining: 3m 13s\n",
      "694:\tlearn: -0.5366274\ttotal: 7m 20s\tremaining: 3m 13s\n",
      "695:\tlearn: -0.5365348\ttotal: 7m 20s\tremaining: 3m 12s\n",
      "696:\tlearn: -0.5364496\ttotal: 7m 21s\tremaining: 3m 11s\n",
      "697:\tlearn: -0.5364001\ttotal: 7m 21s\tremaining: 3m 11s\n",
      "698:\tlearn: -0.5363060\ttotal: 7m 22s\tremaining: 3m 10s\n",
      "699:\tlearn: -0.5362330\ttotal: 7m 22s\tremaining: 3m 9s\n",
      "700:\tlearn: -0.5361589\ttotal: 7m 23s\tremaining: 3m 9s\n",
      "701:\tlearn: -0.5359472\ttotal: 7m 23s\tremaining: 3m 8s\n",
      "702:\tlearn: -0.5358692\ttotal: 7m 24s\tremaining: 3m 7s\n",
      "703:\tlearn: -0.5358262\ttotal: 7m 24s\tremaining: 3m 7s\n",
      "704:\tlearn: -0.5357410\ttotal: 7m 25s\tremaining: 3m 6s\n",
      "705:\tlearn: -0.5355917\ttotal: 7m 25s\tremaining: 3m 5s\n",
      "706:\tlearn: -0.5355102\ttotal: 7m 26s\tremaining: 3m 5s\n",
      "707:\tlearn: -0.5354324\ttotal: 7m 26s\tremaining: 3m 4s\n",
      "708:\tlearn: -0.5354155\ttotal: 7m 27s\tremaining: 3m 3s\n",
      "709:\tlearn: -0.5353243\ttotal: 7m 27s\tremaining: 3m 2s\n",
      "710:\tlearn: -0.5352836\ttotal: 7m 28s\tremaining: 3m 2s\n",
      "711:\tlearn: -0.5352455\ttotal: 7m 28s\tremaining: 3m 1s\n",
      "712:\tlearn: -0.5351847\ttotal: 7m 29s\tremaining: 3m\n",
      "713:\tlearn: -0.5351242\ttotal: 7m 29s\tremaining: 3m\n",
      "714:\tlearn: -0.5350552\ttotal: 7m 30s\tremaining: 2m 59s\n",
      "715:\tlearn: -0.5350021\ttotal: 7m 30s\tremaining: 2m 58s\n",
      "716:\tlearn: -0.5349239\ttotal: 7m 31s\tremaining: 2m 58s\n",
      "717:\tlearn: -0.5347872\ttotal: 7m 32s\tremaining: 2m 57s\n",
      "718:\tlearn: -0.5347342\ttotal: 7m 32s\tremaining: 2m 56s\n",
      "719:\tlearn: -0.5346919\ttotal: 7m 33s\tremaining: 2m 56s\n",
      "720:\tlearn: -0.5346116\ttotal: 7m 33s\tremaining: 2m 55s\n",
      "721:\tlearn: -0.5344830\ttotal: 7m 34s\tremaining: 2m 54s\n",
      "722:\tlearn: -0.5344525\ttotal: 7m 34s\tremaining: 2m 54s\n",
      "723:\tlearn: -0.5343822\ttotal: 7m 35s\tremaining: 2m 53s\n",
      "724:\tlearn: -0.5343366\ttotal: 7m 35s\tremaining: 2m 52s\n",
      "725:\tlearn: -0.5342736\ttotal: 7m 35s\tremaining: 2m 52s\n",
      "726:\tlearn: -0.5342113\ttotal: 7m 36s\tremaining: 2m 51s\n",
      "727:\tlearn: -0.5341815\ttotal: 7m 37s\tremaining: 2m 50s\n",
      "728:\tlearn: -0.5340068\ttotal: 7m 37s\tremaining: 2m 50s\n",
      "729:\tlearn: -0.5339470\ttotal: 7m 37s\tremaining: 2m 49s\n",
      "730:\tlearn: -0.5338762\ttotal: 7m 38s\tremaining: 2m 48s\n",
      "731:\tlearn: -0.5338502\ttotal: 7m 39s\tremaining: 2m 48s\n",
      "732:\tlearn: -0.5337272\ttotal: 7m 39s\tremaining: 2m 47s\n",
      "733:\tlearn: -0.5336121\ttotal: 7m 40s\tremaining: 2m 46s\n",
      "734:\tlearn: -0.5335618\ttotal: 7m 40s\tremaining: 2m 46s\n",
      "735:\tlearn: -0.5334447\ttotal: 7m 41s\tremaining: 2m 45s\n",
      "736:\tlearn: -0.5333781\ttotal: 7m 41s\tremaining: 2m 44s\n",
      "737:\tlearn: -0.5333251\ttotal: 7m 42s\tremaining: 2m 44s\n",
      "738:\tlearn: -0.5332547\ttotal: 7m 42s\tremaining: 2m 43s\n",
      "739:\tlearn: -0.5332235\ttotal: 7m 43s\tremaining: 2m 42s\n",
      "740:\tlearn: -0.5331053\ttotal: 7m 43s\tremaining: 2m 42s\n",
      "741:\tlearn: -0.5330306\ttotal: 7m 44s\tremaining: 2m 41s\n",
      "742:\tlearn: -0.5328830\ttotal: 7m 44s\tremaining: 2m 40s\n",
      "743:\tlearn: -0.5328292\ttotal: 7m 45s\tremaining: 2m 40s\n",
      "744:\tlearn: -0.5327620\ttotal: 7m 45s\tremaining: 2m 39s\n",
      "745:\tlearn: -0.5326857\ttotal: 7m 46s\tremaining: 2m 38s\n",
      "746:\tlearn: -0.5326325\ttotal: 7m 46s\tremaining: 2m 37s\n",
      "747:\tlearn: -0.5325084\ttotal: 7m 46s\tremaining: 2m 37s\n",
      "748:\tlearn: -0.5323672\ttotal: 7m 47s\tremaining: 2m 36s\n",
      "749:\tlearn: -0.5323103\ttotal: 7m 47s\tremaining: 2m 35s\n",
      "750:\tlearn: -0.5322540\ttotal: 7m 48s\tremaining: 2m 35s\n",
      "751:\tlearn: -0.5321812\ttotal: 7m 48s\tremaining: 2m 34s\n",
      "752:\tlearn: -0.5321369\ttotal: 7m 49s\tremaining: 2m 33s\n",
      "753:\tlearn: -0.5320656\ttotal: 7m 49s\tremaining: 2m 33s\n",
      "754:\tlearn: -0.5319765\ttotal: 7m 50s\tremaining: 2m 32s\n",
      "755:\tlearn: -0.5319069\ttotal: 7m 50s\tremaining: 2m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756:\tlearn: -0.5318487\ttotal: 7m 50s\tremaining: 2m 31s\n",
      "757:\tlearn: -0.5317623\ttotal: 7m 51s\tremaining: 2m 30s\n",
      "758:\tlearn: -0.5317090\ttotal: 7m 51s\tremaining: 2m 29s\n",
      "759:\tlearn: -0.5316335\ttotal: 7m 52s\tremaining: 2m 29s\n",
      "760:\tlearn: -0.5315586\ttotal: 7m 52s\tremaining: 2m 28s\n",
      "761:\tlearn: -0.5314944\ttotal: 7m 53s\tremaining: 2m 27s\n",
      "762:\tlearn: -0.5313798\ttotal: 7m 53s\tremaining: 2m 27s\n",
      "763:\tlearn: -0.5313101\ttotal: 7m 54s\tremaining: 2m 26s\n",
      "764:\tlearn: -0.5312599\ttotal: 7m 54s\tremaining: 2m 25s\n",
      "765:\tlearn: -0.5311898\ttotal: 7m 55s\tremaining: 2m 25s\n",
      "766:\tlearn: -0.5311704\ttotal: 7m 55s\tremaining: 2m 24s\n",
      "767:\tlearn: -0.5310780\ttotal: 7m 55s\tremaining: 2m 23s\n",
      "768:\tlearn: -0.5309683\ttotal: 7m 56s\tremaining: 2m 23s\n",
      "769:\tlearn: -0.5308551\ttotal: 7m 56s\tremaining: 2m 22s\n",
      "770:\tlearn: -0.5307685\ttotal: 7m 57s\tremaining: 2m 21s\n",
      "771:\tlearn: -0.5307227\ttotal: 7m 57s\tremaining: 2m 21s\n",
      "772:\tlearn: -0.5306401\ttotal: 7m 58s\tremaining: 2m 20s\n",
      "773:\tlearn: -0.5305532\ttotal: 7m 58s\tremaining: 2m 19s\n",
      "774:\tlearn: -0.5304760\ttotal: 7m 59s\tremaining: 2m 19s\n",
      "775:\tlearn: -0.5304685\ttotal: 7m 59s\tremaining: 2m 18s\n",
      "776:\tlearn: -0.5304221\ttotal: 7m 59s\tremaining: 2m 17s\n",
      "777:\tlearn: -0.5303207\ttotal: 8m\tremaining: 2m 17s\n",
      "778:\tlearn: -0.5302210\ttotal: 8m\tremaining: 2m 16s\n",
      "779:\tlearn: -0.5301805\ttotal: 8m 1s\tremaining: 2m 15s\n",
      "780:\tlearn: -0.5301065\ttotal: 8m 1s\tremaining: 2m 15s\n",
      "781:\tlearn: -0.5300514\ttotal: 8m 2s\tremaining: 2m 14s\n",
      "782:\tlearn: -0.5299713\ttotal: 8m 2s\tremaining: 2m 13s\n",
      "783:\tlearn: -0.5299022\ttotal: 8m 3s\tremaining: 2m 13s\n",
      "784:\tlearn: -0.5298732\ttotal: 8m 3s\tremaining: 2m 12s\n",
      "785:\tlearn: -0.5298621\ttotal: 8m 3s\tremaining: 2m 11s\n",
      "786:\tlearn: -0.5297981\ttotal: 8m 4s\tremaining: 2m 11s\n",
      "787:\tlearn: -0.5297555\ttotal: 8m 4s\tremaining: 2m 10s\n",
      "788:\tlearn: -0.5297323\ttotal: 8m 5s\tremaining: 2m 9s\n",
      "789:\tlearn: -0.5297008\ttotal: 8m 5s\tremaining: 2m 9s\n",
      "790:\tlearn: -0.5296781\ttotal: 8m 6s\tremaining: 2m 8s\n",
      "791:\tlearn: -0.5296532\ttotal: 8m 6s\tremaining: 2m 7s\n",
      "792:\tlearn: -0.5296370\ttotal: 8m 7s\tremaining: 2m 7s\n",
      "793:\tlearn: -0.5296081\ttotal: 8m 7s\tremaining: 2m 6s\n",
      "794:\tlearn: -0.5295464\ttotal: 8m 8s\tremaining: 2m 5s\n",
      "795:\tlearn: -0.5294995\ttotal: 8m 8s\tremaining: 2m 5s\n",
      "796:\tlearn: -0.5294500\ttotal: 8m 9s\tremaining: 2m 4s\n",
      "797:\tlearn: -0.5294151\ttotal: 8m 9s\tremaining: 2m 3s\n",
      "798:\tlearn: -0.5293582\ttotal: 8m 9s\tremaining: 2m 3s\n",
      "799:\tlearn: -0.5292868\ttotal: 8m 10s\tremaining: 2m 2s\n",
      "800:\tlearn: -0.5292048\ttotal: 8m 10s\tremaining: 2m 1s\n",
      "801:\tlearn: -0.5290169\ttotal: 8m 11s\tremaining: 2m 1s\n",
      "802:\tlearn: -0.5289823\ttotal: 8m 11s\tremaining: 2m\n",
      "803:\tlearn: -0.5289514\ttotal: 8m 12s\tremaining: 1m 59s\n",
      "804:\tlearn: -0.5288876\ttotal: 8m 12s\tremaining: 1m 59s\n",
      "805:\tlearn: -0.5288652\ttotal: 8m 13s\tremaining: 1m 58s\n",
      "806:\tlearn: -0.5287914\ttotal: 8m 13s\tremaining: 1m 58s\n",
      "807:\tlearn: -0.5287607\ttotal: 8m 14s\tremaining: 1m 57s\n",
      "808:\tlearn: -0.5286722\ttotal: 8m 14s\tremaining: 1m 56s\n",
      "809:\tlearn: -0.5286391\ttotal: 8m 15s\tremaining: 1m 56s\n",
      "810:\tlearn: -0.5286262\ttotal: 8m 15s\tremaining: 1m 55s\n",
      "811:\tlearn: -0.5285344\ttotal: 8m 16s\tremaining: 1m 54s\n",
      "812:\tlearn: -0.5285116\ttotal: 8m 16s\tremaining: 1m 54s\n",
      "813:\tlearn: -0.5284538\ttotal: 8m 17s\tremaining: 1m 53s\n",
      "814:\tlearn: -0.5284181\ttotal: 8m 17s\tremaining: 1m 53s\n",
      "815:\tlearn: -0.5283520\ttotal: 8m 18s\tremaining: 1m 52s\n",
      "816:\tlearn: -0.5282760\ttotal: 8m 18s\tremaining: 1m 51s\n",
      "817:\tlearn: -0.5282327\ttotal: 8m 19s\tremaining: 1m 51s\n",
      "818:\tlearn: -0.5281668\ttotal: 8m 19s\tremaining: 1m 50s\n",
      "819:\tlearn: -0.5281580\ttotal: 8m 20s\tremaining: 1m 49s\n",
      "820:\tlearn: -0.5280999\ttotal: 8m 20s\tremaining: 1m 49s\n",
      "821:\tlearn: -0.5280731\ttotal: 8m 21s\tremaining: 1m 48s\n",
      "822:\tlearn: -0.5279865\ttotal: 8m 21s\tremaining: 1m 47s\n",
      "823:\tlearn: -0.5279252\ttotal: 8m 22s\tremaining: 1m 47s\n",
      "824:\tlearn: -0.5278759\ttotal: 8m 22s\tremaining: 1m 46s\n",
      "825:\tlearn: -0.5277782\ttotal: 8m 23s\tremaining: 1m 45s\n",
      "826:\tlearn: -0.5277544\ttotal: 8m 23s\tremaining: 1m 45s\n",
      "827:\tlearn: -0.5277468\ttotal: 8m 24s\tremaining: 1m 44s\n",
      "828:\tlearn: -0.5277090\ttotal: 8m 24s\tremaining: 1m 44s\n",
      "829:\tlearn: -0.5276059\ttotal: 8m 25s\tremaining: 1m 43s\n",
      "830:\tlearn: -0.5275606\ttotal: 8m 25s\tremaining: 1m 42s\n",
      "831:\tlearn: -0.5274564\ttotal: 8m 26s\tremaining: 1m 42s\n",
      "832:\tlearn: -0.5273990\ttotal: 8m 26s\tremaining: 1m 41s\n",
      "833:\tlearn: -0.5273628\ttotal: 8m 27s\tremaining: 1m 40s\n",
      "834:\tlearn: -0.5272752\ttotal: 8m 27s\tremaining: 1m 40s\n",
      "835:\tlearn: -0.5271887\ttotal: 8m 28s\tremaining: 1m 39s\n",
      "836:\tlearn: -0.5271526\ttotal: 8m 28s\tremaining: 1m 39s\n",
      "837:\tlearn: -0.5271224\ttotal: 8m 29s\tremaining: 1m 38s\n",
      "838:\tlearn: -0.5270383\ttotal: 8m 29s\tremaining: 1m 37s\n",
      "839:\tlearn: -0.5269961\ttotal: 8m 30s\tremaining: 1m 37s\n",
      "840:\tlearn: -0.5269415\ttotal: 8m 30s\tremaining: 1m 36s\n",
      "841:\tlearn: -0.5268799\ttotal: 8m 30s\tremaining: 1m 35s\n",
      "842:\tlearn: -0.5268035\ttotal: 8m 31s\tremaining: 1m 35s\n",
      "843:\tlearn: -0.5266618\ttotal: 8m 31s\tremaining: 1m 34s\n",
      "844:\tlearn: -0.5266108\ttotal: 8m 32s\tremaining: 1m 34s\n",
      "845:\tlearn: -0.5265392\ttotal: 8m 32s\tremaining: 1m 33s\n",
      "846:\tlearn: -0.5264787\ttotal: 8m 33s\tremaining: 1m 32s\n",
      "847:\tlearn: -0.5263936\ttotal: 8m 34s\tremaining: 1m 32s\n",
      "848:\tlearn: -0.5263306\ttotal: 8m 34s\tremaining: 1m 31s\n",
      "849:\tlearn: -0.5262155\ttotal: 8m 35s\tremaining: 1m 30s\n",
      "850:\tlearn: -0.5261749\ttotal: 8m 35s\tremaining: 1m 30s\n",
      "851:\tlearn: -0.5261110\ttotal: 8m 36s\tremaining: 1m 29s\n",
      "852:\tlearn: -0.5260425\ttotal: 8m 36s\tremaining: 1m 29s\n",
      "853:\tlearn: -0.5260091\ttotal: 8m 37s\tremaining: 1m 28s\n",
      "854:\tlearn: -0.5259449\ttotal: 8m 37s\tremaining: 1m 27s\n",
      "855:\tlearn: -0.5258443\ttotal: 8m 38s\tremaining: 1m 27s\n",
      "856:\tlearn: -0.5257789\ttotal: 8m 38s\tremaining: 1m 26s\n",
      "857:\tlearn: -0.5257495\ttotal: 8m 39s\tremaining: 1m 25s\n",
      "858:\tlearn: -0.5256726\ttotal: 8m 39s\tremaining: 1m 25s\n",
      "859:\tlearn: -0.5255968\ttotal: 8m 40s\tremaining: 1m 24s\n",
      "860:\tlearn: -0.5255316\ttotal: 8m 40s\tremaining: 1m 24s\n",
      "861:\tlearn: -0.5254666\ttotal: 8m 41s\tremaining: 1m 23s\n",
      "862:\tlearn: -0.5253864\ttotal: 8m 41s\tremaining: 1m 22s\n",
      "863:\tlearn: -0.5253326\ttotal: 8m 41s\tremaining: 1m 22s\n",
      "864:\tlearn: -0.5253048\ttotal: 8m 42s\tremaining: 1m 21s\n",
      "865:\tlearn: -0.5252525\ttotal: 8m 42s\tremaining: 1m 20s\n",
      "866:\tlearn: -0.5252332\ttotal: 8m 43s\tremaining: 1m 20s\n",
      "867:\tlearn: -0.5251046\ttotal: 8m 43s\tremaining: 1m 19s\n",
      "868:\tlearn: -0.5250825\ttotal: 8m 44s\tremaining: 1m 19s\n",
      "869:\tlearn: -0.5250304\ttotal: 8m 44s\tremaining: 1m 18s\n",
      "870:\tlearn: -0.5249598\ttotal: 8m 45s\tremaining: 1m 17s\n",
      "871:\tlearn: -0.5248778\ttotal: 8m 45s\tremaining: 1m 17s\n",
      "872:\tlearn: -0.5248465\ttotal: 8m 46s\tremaining: 1m 16s\n",
      "873:\tlearn: -0.5248075\ttotal: 8m 46s\tremaining: 1m 15s\n",
      "874:\tlearn: -0.5247461\ttotal: 8m 47s\tremaining: 1m 15s\n",
      "875:\tlearn: -0.5246336\ttotal: 8m 47s\tremaining: 1m 14s\n",
      "876:\tlearn: -0.5246058\ttotal: 8m 48s\tremaining: 1m 14s\n",
      "877:\tlearn: -0.5245304\ttotal: 8m 48s\tremaining: 1m 13s\n",
      "878:\tlearn: -0.5244625\ttotal: 8m 49s\tremaining: 1m 12s\n",
      "879:\tlearn: -0.5244040\ttotal: 8m 49s\tremaining: 1m 12s\n",
      "880:\tlearn: -0.5243690\ttotal: 8m 50s\tremaining: 1m 11s\n",
      "881:\tlearn: -0.5243416\ttotal: 8m 50s\tremaining: 1m 11s\n",
      "882:\tlearn: -0.5242956\ttotal: 8m 51s\tremaining: 1m 10s\n",
      "883:\tlearn: -0.5242326\ttotal: 8m 51s\tremaining: 1m 9s\n",
      "884:\tlearn: -0.5242017\ttotal: 8m 52s\tremaining: 1m 9s\n",
      "885:\tlearn: -0.5241812\ttotal: 8m 52s\tremaining: 1m 8s\n",
      "886:\tlearn: -0.5241052\ttotal: 8m 53s\tremaining: 1m 7s\n",
      "887:\tlearn: -0.5240789\ttotal: 8m 54s\tremaining: 1m 7s\n",
      "888:\tlearn: -0.5240043\ttotal: 8m 54s\tremaining: 1m 6s\n",
      "889:\tlearn: -0.5239624\ttotal: 8m 54s\tremaining: 1m 6s\n",
      "890:\tlearn: -0.5239133\ttotal: 8m 55s\tremaining: 1m 5s\n",
      "891:\tlearn: -0.5238393\ttotal: 8m 55s\tremaining: 1m 4s\n",
      "892:\tlearn: -0.5238109\ttotal: 8m 56s\tremaining: 1m 4s\n",
      "893:\tlearn: -0.5237401\ttotal: 8m 57s\tremaining: 1m 3s\n",
      "894:\tlearn: -0.5237193\ttotal: 8m 57s\tremaining: 1m 3s\n",
      "895:\tlearn: -0.5236850\ttotal: 8m 58s\tremaining: 1m 2s\n",
      "896:\tlearn: -0.5236425\ttotal: 8m 58s\tremaining: 1m 1s\n",
      "897:\tlearn: -0.5236013\ttotal: 8m 59s\tremaining: 1m 1s\n",
      "898:\tlearn: -0.5234884\ttotal: 8m 59s\tremaining: 1m\n",
      "899:\tlearn: -0.5234474\ttotal: 9m\tremaining: 1m\n",
      "900:\tlearn: -0.5233832\ttotal: 9m\tremaining: 59.4s\n",
      "901:\tlearn: -0.5233659\ttotal: 9m 1s\tremaining: 58.8s\n",
      "902:\tlearn: -0.5232691\ttotal: 9m 1s\tremaining: 58.2s\n",
      "903:\tlearn: -0.5231936\ttotal: 9m 2s\tremaining: 57.6s\n",
      "904:\tlearn: -0.5231028\ttotal: 9m 2s\tremaining: 56.9s\n",
      "905:\tlearn: -0.5230333\ttotal: 9m 3s\tremaining: 56.3s\n",
      "906:\tlearn: -0.5229587\ttotal: 9m 3s\tremaining: 55.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907:\tlearn: -0.5228964\ttotal: 9m 4s\tremaining: 55.1s\n",
      "908:\tlearn: -0.5228134\ttotal: 9m 4s\tremaining: 54.5s\n",
      "909:\tlearn: -0.5227624\ttotal: 9m 5s\tremaining: 53.9s\n",
      "910:\tlearn: -0.5227168\ttotal: 9m 5s\tremaining: 53.3s\n",
      "911:\tlearn: -0.5226322\ttotal: 9m 6s\tremaining: 52.7s\n",
      "912:\tlearn: -0.5225485\ttotal: 9m 6s\tremaining: 52.1s\n",
      "913:\tlearn: -0.5225034\ttotal: 9m 7s\tremaining: 51.5s\n",
      "914:\tlearn: -0.5223772\ttotal: 9m 7s\tremaining: 50.9s\n",
      "915:\tlearn: -0.5223262\ttotal: 9m 8s\tremaining: 50.3s\n",
      "916:\tlearn: -0.5222923\ttotal: 9m 8s\tremaining: 49.6s\n",
      "917:\tlearn: -0.5222108\ttotal: 9m 9s\tremaining: 49s\n",
      "918:\tlearn: -0.5221443\ttotal: 9m 9s\tremaining: 48.4s\n",
      "919:\tlearn: -0.5221035\ttotal: 9m 10s\tremaining: 47.8s\n",
      "920:\tlearn: -0.5220710\ttotal: 9m 10s\tremaining: 47.2s\n",
      "921:\tlearn: -0.5220486\ttotal: 9m 11s\tremaining: 46.6s\n",
      "922:\tlearn: -0.5219125\ttotal: 9m 11s\tremaining: 46s\n",
      "923:\tlearn: -0.5218877\ttotal: 9m 12s\tremaining: 45.4s\n",
      "924:\tlearn: -0.5218328\ttotal: 9m 12s\tremaining: 44.8s\n",
      "925:\tlearn: -0.5217929\ttotal: 9m 13s\tremaining: 44.2s\n",
      "926:\tlearn: -0.5217612\ttotal: 9m 13s\tremaining: 43.6s\n",
      "927:\tlearn: -0.5216776\ttotal: 9m 14s\tremaining: 43s\n",
      "928:\tlearn: -0.5216228\ttotal: 9m 14s\tremaining: 42.4s\n",
      "929:\tlearn: -0.5215170\ttotal: 9m 15s\tremaining: 41.8s\n",
      "930:\tlearn: -0.5214565\ttotal: 9m 15s\tremaining: 41.2s\n",
      "931:\tlearn: -0.5214225\ttotal: 9m 16s\tremaining: 40.6s\n",
      "932:\tlearn: -0.5214073\ttotal: 9m 16s\tremaining: 40s\n",
      "933:\tlearn: -0.5213627\ttotal: 9m 17s\tremaining: 39.4s\n",
      "934:\tlearn: -0.5212860\ttotal: 9m 17s\tremaining: 38.8s\n",
      "935:\tlearn: -0.5212678\ttotal: 9m 18s\tremaining: 38.2s\n",
      "936:\tlearn: -0.5212412\ttotal: 9m 18s\tremaining: 37.6s\n",
      "937:\tlearn: -0.5212126\ttotal: 9m 19s\tremaining: 37s\n",
      "938:\tlearn: -0.5211449\ttotal: 9m 19s\tremaining: 36.4s\n",
      "939:\tlearn: -0.5211325\ttotal: 9m 20s\tremaining: 35.8s\n",
      "940:\tlearn: -0.5210567\ttotal: 9m 20s\tremaining: 35.2s\n",
      "941:\tlearn: -0.5210328\ttotal: 9m 21s\tremaining: 34.6s\n",
      "942:\tlearn: -0.5209822\ttotal: 9m 21s\tremaining: 34s\n",
      "943:\tlearn: -0.5209611\ttotal: 9m 22s\tremaining: 33.4s\n",
      "944:\tlearn: -0.5209219\ttotal: 9m 22s\tremaining: 32.7s\n",
      "945:\tlearn: -0.5208689\ttotal: 9m 23s\tremaining: 32.1s\n",
      "946:\tlearn: -0.5208325\ttotal: 9m 23s\tremaining: 31.5s\n",
      "947:\tlearn: -0.5207960\ttotal: 9m 24s\tremaining: 30.9s\n",
      "948:\tlearn: -0.5206997\ttotal: 9m 24s\tremaining: 30.3s\n",
      "949:\tlearn: -0.5206653\ttotal: 9m 25s\tremaining: 29.7s\n",
      "950:\tlearn: -0.5206459\ttotal: 9m 25s\tremaining: 29.1s\n",
      "951:\tlearn: -0.5206203\ttotal: 9m 26s\tremaining: 28.5s\n",
      "952:\tlearn: -0.5205750\ttotal: 9m 26s\tremaining: 27.9s\n",
      "953:\tlearn: -0.5205476\ttotal: 9m 27s\tremaining: 27.4s\n",
      "954:\tlearn: -0.5205095\ttotal: 9m 27s\tremaining: 26.8s\n",
      "955:\tlearn: -0.5204381\ttotal: 9m 28s\tremaining: 26.2s\n",
      "956:\tlearn: -0.5203459\ttotal: 9m 28s\tremaining: 25.6s\n",
      "957:\tlearn: -0.5202915\ttotal: 9m 29s\tremaining: 25s\n",
      "958:\tlearn: -0.5202225\ttotal: 9m 29s\tremaining: 24.4s\n",
      "959:\tlearn: -0.5201402\ttotal: 9m 30s\tremaining: 23.8s\n",
      "960:\tlearn: -0.5200980\ttotal: 9m 30s\tremaining: 23.2s\n",
      "961:\tlearn: -0.5200852\ttotal: 9m 31s\tremaining: 22.6s\n",
      "962:\tlearn: -0.5200183\ttotal: 9m 31s\tremaining: 22s\n",
      "963:\tlearn: -0.5199846\ttotal: 9m 32s\tremaining: 21.4s\n",
      "964:\tlearn: -0.5199582\ttotal: 9m 32s\tremaining: 20.8s\n",
      "965:\tlearn: -0.5198788\ttotal: 9m 33s\tremaining: 20.2s\n",
      "966:\tlearn: -0.5198556\ttotal: 9m 33s\tremaining: 19.6s\n",
      "967:\tlearn: -0.5197733\ttotal: 9m 34s\tremaining: 19s\n",
      "968:\tlearn: -0.5196642\ttotal: 9m 34s\tremaining: 18.4s\n",
      "969:\tlearn: -0.5195924\ttotal: 9m 35s\tremaining: 17.8s\n",
      "970:\tlearn: -0.5195352\ttotal: 9m 35s\tremaining: 17.2s\n",
      "971:\tlearn: -0.5194849\ttotal: 9m 36s\tremaining: 16.6s\n",
      "972:\tlearn: -0.5194107\ttotal: 9m 36s\tremaining: 16s\n",
      "973:\tlearn: -0.5193601\ttotal: 9m 37s\tremaining: 15.4s\n",
      "974:\tlearn: -0.5192820\ttotal: 9m 37s\tremaining: 14.8s\n",
      "975:\tlearn: -0.5192418\ttotal: 9m 38s\tremaining: 14.2s\n",
      "976:\tlearn: -0.5191849\ttotal: 9m 38s\tremaining: 13.6s\n",
      "977:\tlearn: -0.5191509\ttotal: 9m 39s\tremaining: 13s\n",
      "978:\tlearn: -0.5190199\ttotal: 9m 39s\tremaining: 12.4s\n",
      "979:\tlearn: -0.5190026\ttotal: 9m 40s\tremaining: 11.8s\n",
      "980:\tlearn: -0.5189784\ttotal: 9m 40s\tremaining: 11.2s\n",
      "981:\tlearn: -0.5189707\ttotal: 9m 41s\tremaining: 10.7s\n",
      "982:\tlearn: -0.5189453\ttotal: 9m 41s\tremaining: 10.1s\n",
      "983:\tlearn: -0.5188999\ttotal: 9m 42s\tremaining: 9.47s\n",
      "984:\tlearn: -0.5188829\ttotal: 9m 42s\tremaining: 8.88s\n",
      "985:\tlearn: -0.5188578\ttotal: 9m 43s\tremaining: 8.29s\n",
      "986:\tlearn: -0.5188039\ttotal: 9m 44s\tremaining: 7.69s\n",
      "987:\tlearn: -0.5187765\ttotal: 9m 44s\tremaining: 7.1s\n",
      "988:\tlearn: -0.5187384\ttotal: 9m 45s\tremaining: 6.51s\n",
      "989:\tlearn: -0.5186871\ttotal: 9m 45s\tremaining: 5.91s\n",
      "990:\tlearn: -0.5186829\ttotal: 9m 46s\tremaining: 5.32s\n",
      "991:\tlearn: -0.5186660\ttotal: 9m 46s\tremaining: 4.73s\n",
      "992:\tlearn: -0.5186484\ttotal: 9m 46s\tremaining: 4.14s\n",
      "993:\tlearn: -0.5185877\ttotal: 9m 47s\tremaining: 3.55s\n",
      "994:\tlearn: -0.5185297\ttotal: 9m 47s\tremaining: 2.95s\n",
      "995:\tlearn: -0.5184339\ttotal: 9m 48s\tremaining: 2.36s\n",
      "996:\tlearn: -0.5183908\ttotal: 9m 48s\tremaining: 1.77s\n",
      "997:\tlearn: -0.5183468\ttotal: 9m 49s\tremaining: 1.18s\n",
      "998:\tlearn: -0.5182983\ttotal: 9m 50s\tremaining: 591ms\n",
      "999:\tlearn: -0.5182473\ttotal: 9m 50s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1260d2c88>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "params = {'depth': [4, 7, 10],\n",
    "          'learning_rate' : [0.03, 0.1, 0.15],\n",
    "         'l2_leaf_reg': [1,4,9],\n",
    "         'iterations': [300]}\n",
    "cb = cb.CatBoostClassifier(loss_function='MultiClass', cat_features=categorial)\n",
    "cb.fit(X_train, y_train)\n",
    "#cb_model = RandomizedSearchCV(cb, params, scoring=\"roc_auc\", cv = 3, n_jobs=4)\n",
    "#cb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:4239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=cb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7842567084991328"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      7458\n",
      "           1       0.64      0.19      0.29      1425\n",
      "           2       0.77      0.91      0.83     10719\n",
      "\n",
      "    accuracy                           0.78     19602\n",
      "   macro avg       0.74      0.61      0.63     19602\n",
      "weighted avg       0.78      0.78      0.77     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "With Categorical features\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "clf.fit(train,y_train)\n",
    "auc(clf, train, test)\n",
    "\n",
    "With Categorical features\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=31, \\\n",
    "                            depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "clf.fit(train,y_train, cat_features= cat_features_index)\n",
    "auc(clf, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-b9d484fd07c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiving\u001b[0m \u001b[0man\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m               \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0merror_score\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'raise'\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'raise-deprecating'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mValue\u001b[0m \u001b[0mto\u001b[0m \u001b[0massign\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m \u001b[0moccurs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mRun\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_test_samples\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0mreturn_times\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mboolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscore\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0msparse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mUse\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mmatrices\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0mfloats\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moptimal\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0many\u001b[0m \u001b[0mother\u001b[0m \u001b[0minput\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mcopied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m \u001b[0msolvers\u001b[0m \u001b[0msupport\u001b[0m \u001b[0monly\u001b[0m \u001b[0mL2\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'binary'\u001b[0m  \u001b[0;31m# [1, 2] or [[\"a\"], [\"b\"]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marraysetops\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mother\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                             \u001b[0mperforming\u001b[0m \u001b[0mset\u001b[0m \u001b[0moperations\u001b[0m \u001b[0mon\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mNotes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f{i}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mconsolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=-1)))\n",
    "\n",
    "\n",
    "#testing models\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAJcCAYAAADHBwP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b9cc9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Compare Algorithms\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "plt.title('Comparison of Classification Algorithms')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.boxplot(results)\n",
    "#ax = fig.add_subplot(111)\n",
    "plt.xlabel(names)\n",
    "#ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: catboost: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!catboost -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object '_catboost._FloatArrayWrapper' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-7da22628b62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/catboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEFstrType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_models\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'FeaturesData'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EFstrType'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostClassifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostRegressor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatboostError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# API compatibility alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0m_catboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_catboost_bin_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0m_PoolBase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PoolBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0m_CatBoost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CatBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mget_catboost_bin_module\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mso_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mso_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mloaded_catboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_catboost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'catboost._catboost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36minit _catboost\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object '_catboost._FloatArrayWrapper' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47964843,  0.61985911,  0.65645296, ...,  0.65175665,\n",
       "        0.65085438,  0.65070334])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-f19a6f9bfeb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.86      0.83     10719\n",
      "functional needs repair       0.48      0.35      0.40      1425\n",
      "         non functional       0.81      0.75      0.78      7458\n",
      "\n",
      "            avg / total       0.78      0.78      0.78     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAE9CAYAAAB5m7WdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIl5R6ImIVxR6IuIVhZ6IeEWhJyJe+X8EP3bq8xtx8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b90dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i,\n",
    "               s=confmat[i,j],\n",
    "               va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['public_meeting_False', 'public_meeting_True', 'permit_False',\n",
       "       'permit_True', 'quantity_enough', 'quantity_insufficient',\n",
       "       'quantity_other', 'quantity_seasonal',\n",
       "       'waterpoint_type_communal standpipe',\n",
       "       'waterpoint_type_communal standpipe multiple',\n",
       "       'waterpoint_type_hand pump', 'waterpoint_type_improved spring',\n",
       "       'waterpoint_type_other', 'quality_group_colored',\n",
       "       'quality_group_fluoride', 'quality_group_good',\n",
       "       'quality_group_milky', 'quality_group_other', 'quality_group_salty',\n",
       "       'basin_internal', 'basin_lake nyasa', 'basin_lake rukwa',\n",
       "       'basin_lake tanganyika', 'basin_lake victoria', 'basin_pangani',\n",
       "       'basin_rufiji', 'basin_ruvuma / southern coast',\n",
       "       'basin_wami / ruvu', 'source_dam', 'source_hand dtw', 'source_lake',\n",
       "       'source_machine dbh', 'source_other', 'source_rainwater harvesting',\n",
       "       'source_river', 'source_shallow well', 'source_spring',\n",
       "       'scheme_management_company', 'scheme_management_other',\n",
       "       'scheme_management_parastatal',\n",
       "       'scheme_management_private operator', 'scheme_management_swc',\n",
       "       'scheme_management_trust', 'scheme_management_vwc',\n",
       "       'scheme_management_water authority',\n",
       "       'scheme_management_water board', 'scheme_management_wua',\n",
       "       'scheme_management_wug', 'extraction_type_afridev',\n",
       "       'extraction_type_cemo', 'extraction_type_gravity',\n",
       "       'extraction_type_india mark ii', 'extraction_type_india mark iii',\n",
       "       'extraction_type_ksb', 'extraction_type_mono',\n",
       "       'extraction_type_nira/tanira', 'extraction_type_other',\n",
       "       'extraction_type_other - play pump',\n",
       "       'extraction_type_other - rope pump',\n",
       "       'extraction_type_other - swn 81', 'extraction_type_submersible',\n",
       "       'extraction_type_swn 80', 'extraction_type_windmill', 'amount_tsh',\n",
       "       'gps_height', 'population', 'payment', 'missed_population',\n",
       "       'approximated_amount_tsh', 'wrong_gps_height', 'wp_in_subvillage',\n",
       "       'wp_in_lga', 'wp_in_ward', 'approximated_construction_year',\n",
       "       'lifetimes'],\n",
       "      dtype='<U43')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insted rf put best model\n",
    "importances = bm.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in bm.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = np.array(list(X_train.columns.values))\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot-encod makes many sparsity columns, and models cound not take them into account\n",
    "# from first article check TargetEncoder\n",
    "# https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a\n",
    "# https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159\n",
    "# for large number of cat_values try binarEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from second how to make pipeline and use H2ORandomForest\n",
    "# drop features which have importance less that 100th feature\n",
    "# third post has Class Prediction Error (CPE) and link to post with NN\n",
    "# concat train and test when we work with data, but in the end separeti them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.fit(df_preproc_t, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0-DP-beer_dataset.ipynb             SubmissionFormat.csv\r\n",
      "1.1-DP_waterpomps.ipynb               beer_reviews.csv\r\n",
      "1.3-DP_waterpomps_simplier.ipynb      prepeared_features.csv\r\n",
      "1.4-DP_work_with_cats_features.ipynb  target.csv\r\n",
      "2.0-DP_raw_data_visualization.ipynb   test.csv\r\n",
      "2.1-DP_prepare_data.ipynb             train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_numeric_features(df):\n",
    "    df['missed_population'] = np.where(np.isnan(df['population']), 1, 0)\n",
    "    df['population'].fillna(0, inplace = True)\n",
    "    df['approximated_amount_tsh'] = np.where(np.isnan(df['amount_tsh']), 1, 0) \n",
    "    replacements = df.groupby('water_quality').amount_tsh.agg(pd.Series.mode).to_dict()\n",
    "    replacements.pop('fluoride abandoned')\n",
    "    df.loc[df['water_quality'] != 'soft', 'amount_tsh'] = \\\n",
    "        df.loc[df['water_quality'] != 'soft', 'amount_tsh'].fillna(replacements)\n",
    "    df['amount_tsh'].fillna(0, inplace=True)\n",
    "    df['wrong_gps_height'] = np.where(df['gps_height'] < 0, 1, 0) \n",
    "    df['gps_height'] = abs(df['gps_height'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_categorical_features(df, categoricals):\n",
    "    df[categoricals] = df[categoricals].astype('str')\n",
    "    df[categoricals] = df[categoricals].applymap(lambda x: x.lower())\n",
    "    nan_list = ['not known','unknown','none','-','##','not kno','unknown installer', '0', 'dwe']\n",
    "    df = df.replace(nan_list, np.nan)\n",
    "\n",
    "    # Any feature values with fewer than 50 rows would be turned into a 'other'\n",
    "    for feature in df[categoricals]:\n",
    "        # Determine which feature values to keep\n",
    "        remove = df[feature].value_counts()[df[feature].value_counts() < 50].index.tolist()\n",
    "        #print(remove)\n",
    "        #to_keep = train[feature].value_counts()[train[feature].value_counts() > 50].index.tolist()\n",
    "\n",
    "        # Turn those into NANs (using a copy, to prevent warnings)\n",
    "        feature_copy = df[feature].copy()\n",
    "        #feature_copy[~feature_copy.isin(to_keep)] = np.nan\n",
    "        feature_copy[feature_copy.isin(remove)] = np.nan\n",
    "        #print(feature_copy.isnull().sum())\n",
    "        df[feature] = feature_copy\n",
    "    # Fix all NANs\n",
    "    df[categoricals] = df[categoricals].fillna('other') \n",
    "    df.management_group = df.management_group.apply(lambda x: 'other' if x != 'user-group' else x)\n",
    "    unpayable_types = ['never pay', 'other']\n",
    "    df.payment = df.payment.apply(lambda x: 0 if x in unpayable_types else 1)\n",
    "    df.quantity.replace({'dry': 'other'}, inplace=True)\n",
    "    df.waterpoint_type.replace({'cattle trough':'improved spring'}, inplace=True)\n",
    "    df.drop(['region', 'district_code', 'extraction_type_group', 'extraction_type_class', 'management', \n",
    "             'management_group', 'payment_type', 'water_quality', 'quantity_group', 'source_class', 'source_type',\n",
    "             'waterpoint_type_group'], 1, inplace=True)\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data_features(test_df, train_df):\n",
    "    train_df_temp = train_df.copy()\n",
    "    test_df[['date_recorded', 'construction_year']]= test_df[['date_recorded', 'construction_year']].apply((pd.to_datetime))\n",
    "    train_df_temp['id'] = 0\n",
    "    df = test_df.append(train_df_temp)\n",
    "    df.construction_year.fillna(0, inplace=True)\n",
    "    df.construction_year = df.construction_year.astype(int)\n",
    "    df.construction_year = df.construction_year.replace(0, np.NaN)\n",
    "    df['approximated_construction_year'] = df['construction_year'].apply(lambda x: 1 if np.isnan(x) else 0)\n",
    "    replacements = df.groupby(['funder', 'installer'])['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    replacements = df.groupby('installer')['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    replacements = df.groupby('funder')['construction_year'].transform('mean').round(0)\n",
    "    df['construction_year'] = df['construction_year'].fillna(replacements)\n",
    "\n",
    "    df.construction_year.fillna(df.construction_year.mode()[0], inplace=True)\n",
    "\n",
    "    return df[df.id != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_numeric_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_categorical_features(test_prep, categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prep = prepare_data_features(test_prep, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of 'prefix' (12) did not match the length of the columns being encoded (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-aee6b873864a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dum_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dum_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                                                        len(columns_to_encode)))\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix_sep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mcheck_len\u001b[0;34m(item, name)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                     raise ValueError(length_msg.format(name, len(item),\n\u001b[0;32m-> 1184\u001b[0;31m                                                        len(columns_to_encode)))\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prefix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of 'prefix' (12) did not match the length of the columns being encoded (32)."
     ]
    }
   ],
   "source": [
    "train_dum_t = pd.get_dummies(test_prep, dummy_na=False, prefix = categorial)\n",
    "train_dum_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 4153)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        50785\n",
       "1        51630\n",
       "2        17168\n",
       "3        45559\n",
       "4        49871\n",
       "5        52449\n",
       "6        24806\n",
       "7        28965\n",
       "8        36301\n",
       "9        54122\n",
       "10         419\n",
       "11       45750\n",
       "12         653\n",
       "13       14017\n",
       "14       44607\n",
       "15       40228\n",
       "16       27714\n",
       "17       28785\n",
       "18       28330\n",
       "19       18532\n",
       "20       69961\n",
       "21       55083\n",
       "22        8691\n",
       "23       30331\n",
       "24       70970\n",
       "25       61136\n",
       "26       28799\n",
       "27       46825\n",
       "28       44718\n",
       "29       37350\n",
       "         ...  \n",
       "14820    52228\n",
       "14821    70038\n",
       "14822    25901\n",
       "14823    21131\n",
       "14824    26580\n",
       "14825    66059\n",
       "14826    32944\n",
       "14827    13686\n",
       "14828     8471\n",
       "14829    19620\n",
       "14830    74162\n",
       "14831    37994\n",
       "14832    71151\n",
       "14833    45017\n",
       "14834    12592\n",
       "14835    58693\n",
       "14836    57539\n",
       "14837    71252\n",
       "14838     7869\n",
       "14839    57316\n",
       "14840    59757\n",
       "14841    64579\n",
       "14842    57731\n",
       "14843    65541\n",
       "14844    68174\n",
       "14845    39307\n",
       "14846    18990\n",
       "14847    28749\n",
       "14848    33492\n",
       "14849    68707\n",
       "Name: id, Length: 14850, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prep.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use get_dummies for test and train togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Kwa Mzee Chagala'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-685d205f83e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    298\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Kwa Mzee Chagala'"
     ]
    }
   ],
   "source": [
    "pred = lrc.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### or date recorder could be limitation of construction year\n",
    "# Any feature values with fewer than 50 rows gets turned into a NAN, but this value better to test on cross-validation\n",
    "# later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
